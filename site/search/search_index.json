{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"]},"docs":[{"location":"","title":"News ETL Pipeline \ud83d\udcf0","text":"<p>Bem-vindo \u00e0 documenta\u00e7\u00e3o do pipeline ETL para extra\u00e7\u00e3o e an\u00e1lise de not\u00edcias sobre acidentes com \u00e1lcool.</p>"},{"location":"#visao-geral","title":"Vis\u00e3o Geral","text":"<p>Este projeto implementa um pipeline completo de extra\u00e7\u00e3o, transforma\u00e7\u00e3o e carregamento (ETL) de not\u00edcias relacionadas a acidentes de tr\u00e2nsito envolvendo \u00e1lcool. O pipeline segue princ\u00edpios SOLID de design, tornando-o modular, manuten\u00edvel e extens\u00edvel.</p>"},{"location":"#caracteristicas-principais","title":"Caracter\u00edsticas Principais","text":"<ul> <li>\ud83d\udd0d Extra\u00e7\u00e3o - Coleta de dados de m\u00faltiplas fontes de not\u00edcias (NewsAPI, GNews)</li> <li>\u2699\ufe0f Transforma\u00e7\u00e3o - Processamento, limpeza e classifica\u00e7\u00e3o das not\u00edcias</li> <li>\ud83d\udcbe Carregamento - Armazenamento em PostgreSQL e Amazon S3</li> <li>\ud83d\udd04 Orquestra\u00e7\u00e3o - Automa\u00e7\u00e3o do fluxo de trabalho com Apache Airflow</li> <li>\ud83e\uddf1 Arquitetura SOLID - Design orientado a interfaces para alta coes\u00e3o e baixo acoplamento</li> </ul>"},{"location":"#tecnologias-utilizadas","title":"Tecnologias Utilizadas","text":"<ul> <li>Python 3.7+</li> <li>Apache Airflow</li> <li>PostgreSQL</li> <li>Amazon S3</li> <li>Docker e Docker Compose</li> </ul>"},{"location":"#comecando","title":"Come\u00e7ando","text":"<p>Para executar este projeto localmente:</p> <pre><code># Clonar o reposit\u00f3rio\ngit clone https://github.com/ErickGCA/data-pipeline-news.git\n\n# Navegar at\u00e9 o diret\u00f3rio do projeto\ncd data-pipeline-news\n\n# Iniciar os servi\u00e7os Docker (Airflow, PostgreSQL)\ncd docker\ndocker-compose up -d\n</code></pre> <p>Acesse a interface web do Airflow em http://localhost:8080 para monitorar e executar o pipeline. </p>"},{"location":"architecture/overview/","title":"Vis\u00e3o Geral da Arquitetura","text":"<p>O projeto segue uma arquitetura modular baseada nos princ\u00edpios SOLID, facilitando a manuten\u00e7\u00e3o, testabilidade e extensibilidade.</p>"},{"location":"architecture/overview/#estrutura-do-projeto","title":"Estrutura do Projeto","text":"<pre><code>src/\n\u251c\u2500\u2500 etl/\n\u2502   \u251c\u2500\u2500 extractors/       # Extratores de diferentes fontes de not\u00edcias\n\u2502   \u251c\u2500\u2500 transformers/     # Transformadores para processar not\u00edcias\n\u2502   \u2514\u2500\u2500 loaders/          # Carregadores para diferentes destinos\n\u251c\u2500\u2500 utils/\n\u2502   \u251c\u2500\u2500 config.py         # Gerenciamento de configura\u00e7\u00e3o\n\u2502   \u251c\u2500\u2500 logger.py         # Sistema de logging centralizado\n\u2502   \u2514\u2500\u2500 database.py       # Utilit\u00e1rio para conex\u00e3o com banco de dados\n\u2514\u2500\u2500 __init__.py\n</code></pre>"},{"location":"architecture/overview/#fluxo-de-dados","title":"Fluxo de Dados","text":"<p>O fluxo de dados no pipeline segue estas etapas principais:</p> <ol> <li>Extra\u00e7\u00e3o: Coleta de not\u00edcias de m\u00faltiplas fontes (NewsAPI, GNews)</li> <li>Transforma\u00e7\u00e3o: Processamento e filtragem das not\u00edcias </li> <li>Carregamento: Armazenamento no PostgreSQL e Amazon S3</li> </ol>"},{"location":"architecture/overview/#diagrama-de-componentes","title":"Diagrama de Componentes","text":"<pre><code>\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510     \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510     \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502  Extratores \u2502\u2500\u2500\u2500\u2500&gt;\u2502Transformador\u2502\u2500\u2500\u2500\u2500&gt;\u2502 Carregadores\u2502\n\u2502  (NewsAPI,  \u2502     \u2502    (News)   \u2502     \u2502 (PostgreSQL,\u2502\n\u2502   GNews)    \u2502     \u2502             \u2502     \u2502     S3)     \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518     \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518     \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n        \u2502                  \u2502                   \u2502\n        \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n                           \u25bc\n                    \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n                    \u2502  Utilit\u00e1rios\u2502\n                    \u2502   (Config,  \u2502\n                    \u2502    Logger)  \u2502\n                    \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n</code></pre>"},{"location":"architecture/overview/#orquestracao","title":"Orquestra\u00e7\u00e3o","text":"<p>A orquestra\u00e7\u00e3o do pipeline \u00e9 realizada pelo Apache Airflow atrav\u00e9s de uma DAG (Directed Acyclic Graph) que coordena a execu\u00e7\u00e3o das tarefas de extra\u00e7\u00e3o, transforma\u00e7\u00e3o e carregamento.</p> <pre><code>extract_news \u2500\u2500&gt; transform_news \u2500\u2500\u252c\u2500\u2500&gt; load_to_postgres\n                                  \u2502\n                                  \u2514\u2500\u2500&gt; upload_to_s3\n</code></pre>"},{"location":"architecture/solid/","title":"Princ\u00edpios SOLID no Projeto","text":"<p>Este projeto foi refatorado seguindo os princ\u00edpios SOLID de design de software orientado a objetos, o que resulta em um c\u00f3digo mais manuten\u00edvel, extens\u00edvel e test\u00e1vel.</p>"},{"location":"architecture/solid/#s-principio-da-responsabilidade-unica","title":"S - Princ\u00edpio da Responsabilidade \u00danica","text":"<p>Cada classe no projeto tem uma \u00fanica responsabilidade:</p> <ul> <li>Extratores: Respons\u00e1veis apenas por extrair dados de uma fonte espec\u00edfica</li> <li>Transformadores: Respons\u00e1veis apenas por transformar e processar os dados</li> <li>Carregadores: Respons\u00e1veis apenas por carregar os dados em um destino espec\u00edfico</li> <li>Config: Respons\u00e1vel pelo gerenciamento de configura\u00e7\u00f5es</li> <li>Logger: Respons\u00e1vel pelo sistema de logging</li> </ul>"},{"location":"architecture/solid/#o-principio-abertofechado","title":"O - Princ\u00edpio Aberto/Fechado","text":"<p>O projeto est\u00e1 aberto para extens\u00e3o, mas fechado para modifica\u00e7\u00e3o:</p> <pre><code># Nova fonte de not\u00edcias pode ser adicionada sem modificar o c\u00f3digo existente\nclass CNNExtractor(BaseExtractor):\n    def extract(self, query, from_date, to_date, **kwargs):\n        # Implementa\u00e7\u00e3o espec\u00edfica\n\n    def validate_source(self):\n        # Valida\u00e7\u00e3o espec\u00edfica\n\n    def get_source_name(self):\n        return \"CNN\"\n</code></pre>"},{"location":"architecture/solid/#l-principio-da-substituicao-de-liskov","title":"L - Princ\u00edpio da Substitui\u00e7\u00e3o de Liskov","text":"<p>As implementa\u00e7\u00f5es concretas podem ser substitu\u00eddas pelas suas abstra\u00e7\u00f5es sem afetar o comportamento do programa:</p> <pre><code># Qualquer extrator pode ser usado aqui\ndef process_news(extractor: BaseExtractor, query, from_date, to_date):\n    return extractor.extract(query, from_date, to_date)\n\n# Funciona com qualquer implementa\u00e7\u00e3o\nnews_api_articles = process_news(NewsAPIExtractor(), query, start_date, end_date)\ngnews_articles = process_news(GNewsExtractor(), query, start_date, end_date)\n</code></pre>"},{"location":"architecture/solid/#i-principio-da-segregacao-de-interface","title":"I - Princ\u00edpio da Segrega\u00e7\u00e3o de Interface","text":"<p>As interfaces s\u00e3o espec\u00edficas para seus clientes, evitando m\u00e9todos n\u00e3o utilizados:</p> <ul> <li><code>BaseExtractor</code>: Interface espec\u00edfica para extratores</li> <li><code>BaseTransformer</code>: Interface espec\u00edfica para transformadores</li> <li><code>BaseLoader</code>: Interface espec\u00edfica para carregadores</li> </ul>"},{"location":"architecture/solid/#d-principio-da-inversao-de-dependencia","title":"D - Princ\u00edpio da Invers\u00e3o de Depend\u00eancia","text":"<p>O c\u00f3digo depende de abstra\u00e7\u00f5es, n\u00e3o de implementa\u00e7\u00f5es concretas:</p> <pre><code># A DAG depende das abstra\u00e7\u00f5es, n\u00e3o das implementa\u00e7\u00f5es concretas\ndef extract_news(**kwargs):\n    # NewsAPIExtractor e GNewsExtractor s\u00e3o inicializados aqui,\n    # mas s\u00e3o usados atrav\u00e9s da interface BaseExtractor\n    news_api_extractor = NewsAPIExtractor()\n    gnews_extractor = GNewsExtractor()\n\n    # Extrair usando as interfaces\n    news_api_articles = news_api_extractor.extract(...)\n    gnews_articles = gnews_extractor.extract(...)\n</code></pre>"},{"location":"architecture/solid/#beneficios-da-arquitetura-solid","title":"Benef\u00edcios da Arquitetura SOLID","text":"<ol> <li>Manutenibilidade: F\u00e1cil de entender e modificar</li> <li>Extensibilidade: F\u00e1cil de adicionar novas funcionalidades</li> <li>Testabilidade: F\u00e1cil de testar componentes isoladamente</li> <li>Reutiliza\u00e7\u00e3o: Componentes podem ser reutilizados em outros contextos</li> <li>Flexibilidade: F\u00e1cil de trocar implementa\u00e7\u00f5es </li> </ol>"},{"location":"docker/dags/","title":"DAGs do Airflow","text":"<p>O projeto utiliza Apache Airflow para orquestrar os processos ETL. As DAGs (Directed Acyclic Graphs) definem o fluxo de trabalho e a sequ\u00eancia de tarefas a serem executadas.</p>"},{"location":"docker/dags/#estrutura-de-diretorios","title":"Estrutura de Diret\u00f3rios","text":"<p>As DAGs est\u00e3o localizadas no diret\u00f3rio <code>docker/dags/pipelines/</code>:</p> <pre><code>docker/\n  \u2514\u2500\u2500 dags/\n      \u251c\u2500\u2500 pipelines/\n      \u2502   \u251c\u2500\u2500 news_etl_dag.py        # DAG principal refatorada com SOLID\n      \u2502   \u251c\u2500\u2500 etl_pipeline_dag.py    # DAG anterior\n      \u2502   \u251c\u2500\u2500 extract_news.py        # M\u00f3dulo para extra\u00e7\u00e3o\n      \u2502   \u251c\u2500\u2500 transform_news.py      # M\u00f3dulo para transforma\u00e7\u00e3o\n      \u2502   \u251c\u2500\u2500 load_to_postgres.py    # M\u00f3dulo para carregamento no PostgreSQL\n      \u2502   \u251c\u2500\u2500 upload_to_s3.py        # M\u00f3dulo para upload no S3\n      \u2502   \u2514\u2500\u2500 main_etl.py            # Script ETL monol\u00edtico original\n      \u2514\u2500\u2500 utils/                     # Utilit\u00e1rios\n</code></pre>"},{"location":"docker/dags/#dag-principal-news_etl_dagpy","title":"DAG Principal: news_etl_dag.py","text":"<p>A DAG principal do projeto foi refatorada para usar a nova arquitetura SOLID:</p>"},{"location":"docker/dags/#tarefas","title":"Tarefas","text":"<ol> <li>extract_news - Extrai not\u00edcias de m\u00faltiplas fontes (NewsAPI, GNews)</li> <li>transform_news - Transforma e filtra not\u00edcias para identificar as relevantes</li> <li>load_to_postgres - Carrega not\u00edcias processadas no PostgreSQL</li> <li>upload_to_s3 - Carrega not\u00edcias processadas no Amazon S3</li> </ol>"},{"location":"docker/dags/#fluxo-de-execucao","title":"Fluxo de Execu\u00e7\u00e3o","text":"<pre><code>extract_news \u2500\u2500&gt; transform_news \u2500\u2500\u252c\u2500\u2500&gt; load_to_postgres\n                                  \u2502\n                                  \u2514\u2500\u2500&gt; upload_to_s3\n</code></pre>"},{"location":"docker/dags/#programacao","title":"Programa\u00e7\u00e3o","text":"<p>A DAG \u00e9 executada diariamente \u00e0s 8:00 (UTC):</p> <pre><code>with DAG(\n    dag_id=\"news_etl_pipeline\",\n    default_args=default_args,\n    description=\"ETL Pipeline para extra\u00e7\u00e3o e an\u00e1lise de not\u00edcias sobre acidentes com \u00e1lcool\",\n    schedule_interval=\"0 8 * * *\",  # Diariamente \u00e0s 8:00\n    start_date=days_ago(1),\n    catchup=False,\n    tags=[\"news\", \"etl\", \"solid\"],\n) as dag:\n    # Defini\u00e7\u00e3o das tarefas...\n</code></pre>"},{"location":"docker/dags/#configuracao","title":"Configura\u00e7\u00e3o","text":"<p>As configura\u00e7\u00f5es da DAG s\u00e3o gerenciadas pela classe <code>Config</code>:</p> <pre><code># Inicializar configura\u00e7\u00e3o\nconfig = Config()\n\n# Consulta para busca de not\u00edcias\nNEWS_QUERY = '(acidente OR colis\u00e3o OR batida OR capotamento OR atropelamento) AND (\u00e1lcool OR alcoolizado OR embriaguez OR b\u00eabado OR alcoolemia OR \"lei seca\")'\n</code></pre>"},{"location":"docker/dags/#monitoramento","title":"Monitoramento","text":"<p>O Apache Airflow fornece uma interface web para monitorar a execu\u00e7\u00e3o das DAGs:</p> <ol> <li>Acesse http://localhost:8080</li> <li>Fa\u00e7a login com as credenciais padr\u00e3o (airflow/airflow)</li> <li>V\u00e1 para DAGs &gt; news_etl_pipeline</li> </ol>"},{"location":"docker/dags/#executando-manualmente","title":"Executando Manualmente","text":"<p>Para executar a DAG manualmente:</p> <ol> <li>Na interface web do Airflow, encontre a DAG <code>news_etl_pipeline</code></li> <li>Clique no bot\u00e3o \"Trigger DAG\"</li> <li>Opcional: defina par\u00e2metros adicionais (ex: days_back=3)</li> </ol> <p>Ou use a linha de comando:</p> <pre><code>docker-compose run airflow-cli airflow dags trigger news_etl_pipeline\n</code></pre>"},{"location":"docker/setup/","title":"Configura\u00e7\u00e3o Docker","text":"<p>O projeto utiliza Docker e Docker Compose para criar um ambiente de desenvolvimento completo com Apache Airflow, PostgreSQL e outros servi\u00e7os necess\u00e1rios.</p>"},{"location":"docker/setup/#pre-requisitos","title":"Pr\u00e9-requisitos","text":"<ul> <li>Docker</li> <li>Docker Compose</li> </ul>"},{"location":"docker/setup/#arquivos-de-configuracao","title":"Arquivos de Configura\u00e7\u00e3o","text":"<p>O ambiente \u00e9 definido pelo arquivo <code>docker-compose.yml</code> localizado na pasta <code>docker/</code>.</p>"},{"location":"docker/setup/#servicos","title":"Servi\u00e7os","text":"<p>O Docker Compose configura os seguintes servi\u00e7os:</p> <ul> <li>PostgreSQL: Banco de dados para armazenamento de not\u00edcias processadas</li> <li>Airflow Webserver: Interface web para gerenciamento do Airflow</li> <li>Airflow Scheduler: Programador de tarefas do Airflow</li> <li>Airflow Worker: Executor de tarefas do Airflow</li> <li>Airflow Init: Inicializa\u00e7\u00e3o do Airflow</li> <li>Airflow CLI: Interface de linha de comando para o Airflow</li> </ul>"},{"location":"docker/setup/#volumes","title":"Volumes","text":"<p>Os seguintes volumes s\u00e3o configurados:</p> <ul> <li>./dags: Diret\u00f3rio para armazenar as DAGs do Airflow</li> <li>./logs: Logs do Airflow</li> <li>./plugins: Plugins do Airflow</li> <li>./data: Dados persistentes</li> </ul>"},{"location":"docker/setup/#iniciando-o-ambiente","title":"Iniciando o Ambiente","text":"<p>Para iniciar todos os servi\u00e7os:</p> <pre><code>cd docker\ndocker-compose up -d\n</code></pre> <p>Para verificar o status dos cont\u00eaineres:</p> <pre><code>docker-compose ps\n</code></pre> <p>Para parar todos os servi\u00e7os:</p> <pre><code>docker-compose down\n</code></pre>"},{"location":"docker/setup/#acesso-aos-servicos","title":"Acesso aos Servi\u00e7os","text":"<ul> <li>Airflow Web UI: http://localhost:8080</li> <li>PostgreSQL: localhost:5432</li> </ul>"},{"location":"docker/setup/#customizacao","title":"Customiza\u00e7\u00e3o","text":"<p>Para personalizar o ambiente, voc\u00ea pode editar as seguintes vari\u00e1veis no arquivo <code>docker-compose.yml</code>:</p> <ul> <li>AIRFLOW__CORE__EXECUTOR: Tipo de executor do Airflow</li> <li>AIRFLOW__DATABASE__SQL_ALCHEMY_CONN: String de conex\u00e3o com o banco de dados do Airflow</li> <li>POSTGRES_USER, POSTGRES_PASSWORD, POSTGRES_DB: Credenciais do PostgreSQL </li> </ul>"},{"location":"etl/extractors/","title":"Extratores","text":"<p>Os extratores s\u00e3o respons\u00e1veis por coletar dados de diferentes fontes de not\u00edcias e retorn\u00e1-los em um formato padronizado para processamento posterior.</p>"},{"location":"etl/extractors/#baseextractor","title":"BaseExtractor","text":"<p>A interface base para todos os extratores implementa os seguintes m\u00e9todos:</p> <pre><code>@abstractmethod\ndef extract(self, query: str, from_date: str, to_date: str, **kwargs) -&gt; List[Dict[str, Any]]:\n    \"\"\"Extrai dados da fonte\"\"\"\n\n@abstractmethod\ndef validate_source(self) -&gt; bool:\n    \"\"\"Valida a disponibilidade da fonte\"\"\"\n\n@abstractmethod\ndef get_source_name(self) -&gt; str:\n    \"\"\"Retorna o nome da fonte\"\"\"\n</code></pre>"},{"location":"etl/extractors/#implementacoes-disponiveis","title":"Implementa\u00e7\u00f5es Dispon\u00edveis","text":""},{"location":"etl/extractors/#newsapiextractor","title":"NewsAPIExtractor","text":"<p>Extrator para a API NewsAPI (https://newsapi.org/).</p> <p>Caracter\u00edsticas: - Requer uma chave de API - Suporta filtros por data, idioma e pa\u00eds - Retorna artigos em formato JSON padronizado</p> <p>Exemplo de uso: <pre><code>from src.etl.extractors.news_api_extractor import NewsAPIExtractor\n\nextractor = NewsAPIExtractor()\narticles = extractor.extract(\n    query=\"acidente AND \u00e1lcool\",\n    from_date=\"2023-01-01\",\n    to_date=\"2023-01-10\",\n    language=\"pt\"\n)\n</code></pre></p>"},{"location":"etl/extractors/#gnewsextractor","title":"GNewsExtractor","text":"<p>Extrator para a API GNews (https://gnews.io/).</p> <p>Caracter\u00edsticas: - Requer uma chave de API - Suporta filtros por data, idioma e pa\u00eds - Retorna artigos em formato JSON padronizado</p> <p>Exemplo de uso: <pre><code>from src.etl.extractors.gnews_extractor import GNewsExtractor\n\nextractor = GNewsExtractor()\narticles = extractor.extract(\n    query=\"acidente AND \u00e1lcool\",\n    from_date=\"2023-01-01\",\n    to_date=\"2023-01-10\",\n    language=\"pt\",\n    country=\"br\"\n)\n</code></pre></p>"},{"location":"etl/extractors/#criando-um-novo-extrator","title":"Criando um Novo Extrator","text":"<p>Para criar um novo extrator, basta implementar a interface <code>BaseExtractor</code>:</p> <pre><code>from src.etl.extractors.base_extractor import BaseExtractor\n\nclass MyNewExtractor(BaseExtractor):\n    def extract(self, query, from_date, to_date, **kwargs):\n        # Implementa\u00e7\u00e3o espec\u00edfica para obter dados da fonte\n        # ...\n        return articles\n\n    def validate_source(self):\n        # Verificar se a fonte est\u00e1 dispon\u00edvel\n        # ...\n        return True\n\n    def get_source_name(self):\n        return \"MyNewsSource\"\n</code></pre>"},{"location":"etl/loaders/","title":"Carregadores","text":"<p>Os carregadores s\u00e3o respons\u00e1veis por armazenar os dados processados em diferentes destinos como bancos de dados, servi\u00e7os de armazenamento em nuvem ou arquivos locais.</p>"},{"location":"etl/loaders/#baseloader","title":"BaseLoader","text":"<p>A interface base para todos os carregadores implementa os seguintes m\u00e9todos:</p> <pre><code>@abstractmethod\ndef load(self, data: List[Dict[str, Any]], **kwargs) -&gt; bool:\n    \"\"\"Carrega os dados no destino\"\"\"\n\n@abstractmethod\ndef validate_destination(self) -&gt; bool:\n    \"\"\"Valida se o destino est\u00e1 dispon\u00edvel\"\"\"\n</code></pre>"},{"location":"etl/loaders/#implementacoes-disponiveis","title":"Implementa\u00e7\u00f5es Dispon\u00edveis","text":""},{"location":"etl/loaders/#postgresloader","title":"PostgresLoader","text":"<p>Carregador para armazenamento em banco de dados PostgreSQL.</p> <p>Caracter\u00edsticas: - Criar automaticamente tabelas se n\u00e3o existirem - Suporta diferentes modos de inser\u00e7\u00e3o (append, replace, fail) - Gerencia conex\u00f5es e transa\u00e7\u00f5es - Otimizado para inser\u00e7\u00f5es em lote</p> <p>Exemplo de uso: <pre><code>from src.etl.loaders.postgres_loader import PostgresLoader\n\nloader = PostgresLoader()\nsuccess = loader.load(\n    data=transformed_articles,\n    table_name=\"news_data.processed_news\",\n    if_exists=\"append\"\n)\n</code></pre></p>"},{"location":"etl/loaders/#s3uploader","title":"S3Uploader","text":"<p>Carregador para armazenamento no Amazon S3.</p> <p>Caracter\u00edsticas: - Upload de dados como arquivos JSON ou CSV - Suporte para metadados e tags - Controle de acesso e criptografia - Versionamento autom\u00e1tico</p> <p>Exemplo de uso: <pre><code>from src.etl.loaders.s3_uploader import S3Uploader\n\nuploader = S3Uploader()\nsuccess = uploader.load(\n    data=transformed_articles,\n    object_name=\"news/processed_news_2023-01-01.json\",\n    metadata={\"source\": \"news_pipeline\", \"date\": \"2023-01-01\"}\n)\n</code></pre></p>"},{"location":"etl/loaders/#criando-um-novo-carregador","title":"Criando um Novo Carregador","text":"<p>Para criar um carregador personalizado, implemente a interface <code>BaseLoader</code>:</p> <pre><code>from src.etl.loaders.base_loader import BaseLoader\n\nclass MySQLLoader(BaseLoader):\n    def load(self, data, **kwargs):\n        # C\u00f3digo para carregar dados no MySQL\n        # ...\n        return True\n\n    def validate_destination(self):\n        # Verificar conex\u00e3o com MySQL\n        # ...\n        return True\n</code></pre>"},{"location":"etl/transformers/","title":"Transformadores","text":"<p>Os transformadores s\u00e3o respons\u00e1veis por processar, limpar e enriquecer os dados extra\u00eddos das fontes de not\u00edcias.</p>"},{"location":"etl/transformers/#basetransformer","title":"BaseTransformer","text":"<p>A interface base para todos os transformadores implementa os seguintes m\u00e9todos:</p> <pre><code>@abstractmethod\ndef transform(self, data: List[Dict[str, Any]], **kwargs) -&gt; List[Dict[str, Any]]:\n    \"\"\"Transforma os dados\"\"\"\n\n@abstractmethod\ndef validate_transformation(self, data: List[Dict[str, Any]]) -&gt; bool:\n    \"\"\"Valida os dados transformados\"\"\"\n</code></pre>"},{"location":"etl/transformers/#implementacoes-disponiveis","title":"Implementa\u00e7\u00f5es Dispon\u00edveis","text":""},{"location":"etl/transformers/#newstransformer","title":"NewsTransformer","text":"<p>Transformador espec\u00edfico para not\u00edcias relacionadas a acidentes com \u00e1lcool.</p> <p>Caracter\u00edsticas: - Normaliza formatos de data e hora - Remove duplicatas baseadas em t\u00edtulo ou conte\u00fado - Padroniza campos e formatos - Classifica not\u00edcias por relev\u00e2ncia - Extrai entidades e informa\u00e7\u00f5es adicionais do texto</p> <p>Exemplo de uso: <pre><code>from src.etl.transformers.news_transformer import NewsTransformer\n\ntransformer = NewsTransformer()\ntransformed_articles = transformer.transform(\n    data=articles,\n    deduplicate=True\n)\n</code></pre></p> <p>Pipeline de transforma\u00e7\u00e3o:</p> <p>O <code>NewsTransformer</code> aplica as seguintes etapas de transforma\u00e7\u00e3o:</p> <ol> <li>Normaliza\u00e7\u00e3o de Campos - Padroniza nomes e formatos de campos</li> <li>Limpeza de Texto - Remove HTML, caracteres especiais e formata o texto</li> <li>Detec\u00e7\u00e3o de Duplicatas - Identifica e remove artigos duplicados</li> <li>Classifica\u00e7\u00e3o - Avalia relev\u00e2ncia para o tema (acidentes com \u00e1lcool)</li> <li>Enriquecimento - Adiciona metadados e informa\u00e7\u00f5es extra\u00eddas do texto</li> </ol>"},{"location":"etl/transformers/#criando-um-novo-transformador","title":"Criando um Novo Transformador","text":"<p>Para criar um transformador personalizado, implemente a interface <code>BaseTransformer</code>:</p> <pre><code>from src.etl.transformers.base_transformer import BaseTransformer\n\nclass MyCustomTransformer(BaseTransformer):\n    def transform(self, data, **kwargs):\n        # Implementa\u00e7\u00e3o de transforma\u00e7\u00e3o espec\u00edfica\n        # ...\n        return transformed_data\n\n    def validate_transformation(self, data):\n        # C\u00f3digo para validar os dados transformados\n        # ...\n        return True\n</code></pre>"},{"location":"src/extractors/","title":"Documenta\u00e7\u00e3o da API de Extratores","text":"<p>               Bases: <code>ABC</code></p> <p>Interface base para todos os extratores de dados. Seguindo o princ\u00edpio da Interface Segregation (ISP) do SOLID.</p> Source code in <code>src\\etl\\extractors\\base_extractor.py</code> <pre><code>class BaseExtractor(ABC):\n    \"\"\"\n    Interface base para todos os extratores de dados.\n    Seguindo o princ\u00edpio da Interface Segregation (ISP) do SOLID.\n    \"\"\"\n\n    @abstractmethod\n    def extract(self, query: str, from_date: str, to_date: str, **kwargs) -&gt; List[Dict[str, Any]]:\n        \"\"\"\n        M\u00e9todo para extrair dados de uma fonte.\n\n        Args:\n            query: Consulta para busca de not\u00edcias\n            from_date: Data inicial no formato YYYY-MM-DD\n            to_date: Data final no formato YYYY-MM-DD\n            **kwargs: Par\u00e2metros espec\u00edficos para a extra\u00e7\u00e3o\n\n        Returns:\n            List[Dict[str, Any]]: Lista de artigos extra\u00eddos\n        \"\"\"\n        pass\n\n    @abstractmethod\n    def validate_source(self) -&gt; bool:\n        \"\"\"\n        M\u00e9todo para validar a disponibilidade e autenticidade da fonte.\n\n        Returns:\n            bool: True se a fonte for v\u00e1lida, False caso contr\u00e1rio\n        \"\"\"\n        pass\n\n    @abstractmethod\n    def get_source_name(self) -&gt; str:\n        \"\"\"\n        Retorna o nome da fonte de dados.\n\n        Returns:\n            str: Nome da fonte\n        \"\"\"\n        pass \n</code></pre> <p>               Bases: <code>BaseExtractor</code></p> <p>Extrator de not\u00edcias da API News API. Implementa a interface BaseExtractor.</p> Source code in <code>src\\etl\\extractors\\news_api_extractor.py</code> <pre><code>class NewsAPIExtractor(BaseExtractor):\n    \"\"\"\n    Extrator de not\u00edcias da API News API.\n    Implementa a interface BaseExtractor.\n    \"\"\"\n\n    def __init__(self, api_key: Optional[str] = None):\n        \"\"\"\n        Inicializa o extrator com a chave da API.\n\n        Args:\n            api_key: Chave da API News API (opcional)\n        \"\"\"\n        self.config = Config()\n        self.api_key = api_key or self.config.news_api_key\n\n    def extract(self, query: str, from_date: str, to_date: str, **kwargs) -&gt; List[Dict[str, Any]]:\n        \"\"\"\n        Extrai not\u00edcias da News API.\n\n        Args:\n            query: Consulta para busca de not\u00edcias\n            from_date: Data inicial no formato YYYY-MM-DD\n            to_date: Data final no formato YYYY-MM-DD\n            **kwargs: Par\u00e2metros adicionais (language, page_size)\n\n        Returns:\n            List[Dict[str, Any]]: Lista de artigos extra\u00eddos\n        \"\"\"\n        language = kwargs.get(\"language\", \"pt\")\n        page_size = kwargs.get(\"page_size\", 50)\n\n        if not self.validate_source():\n            logger.error(\"API key inv\u00e1lida ou n\u00e3o configurada\")\n            return []\n\n        logger.info(f\"Buscando not\u00edcias da NewsAPI de {from_date} at\u00e9 {to_date}...\")\n\n        url = (\n            f\"https://newsapi.org/v2/everything?q={query}\"\n            f\"&amp;language={language}&amp;pageSize={page_size}&amp;page=1\"\n            f\"&amp;from={from_date}&amp;to={to_date}&amp;sortBy=relevancy&amp;apiKey={self.api_key}\"\n        )\n        headers = {\"User-Agent\": \"Mozilla/5.0\"}\n\n        try:\n            response = requests.get(url, headers=headers)\n            response.raise_for_status()\n            data = response.json()\n            articles = data.get(\"articles\", [])\n\n            for article in articles:\n                article[\"_source\"] = \"newsapi\"\n\n            logger.info(f\"{len(articles)} artigos encontrados de {from_date} at\u00e9 {to_date}\")\n            return articles\n\n        except Exception as e:\n            logger.error(f\"Erro na extra\u00e7\u00e3o da NewsAPI para o per\u00edodo {from_date} a {to_date}: {e}\")\n            return []\n\n    def validate_source(self) -&gt; bool:\n        \"\"\"\n        Valida se a chave da API est\u00e1 configurada.\n\n        Returns:\n            bool: True se a chave for v\u00e1lida, False caso contr\u00e1rio\n        \"\"\"\n        return bool(self.api_key)\n\n    def get_source_name(self) -&gt; str:\n        \"\"\"\n        Retorna o nome da fonte.\n\n        Returns:\n            str: Nome da fonte\n        \"\"\"\n        return \"NewsAPI\" \n</code></pre> <p>               Bases: <code>BaseExtractor</code></p> <p>Extrator de not\u00edcias da API GNews. Implementa a interface BaseExtractor.</p> Source code in <code>src\\etl\\extractors\\gnews_extractor.py</code> <pre><code>class GNewsExtractor(BaseExtractor):\n    \"\"\"\n    Extrator de not\u00edcias da API GNews.\n    Implementa a interface BaseExtractor.\n    \"\"\"\n\n    def __init__(self, api_key: Optional[str] = None):\n        \"\"\"\n        Inicializa o extrator com a chave da API.\n\n        Args:\n            api_key: Chave da API GNews (opcional)\n        \"\"\"\n        self.config = Config()\n        self.api_key = api_key or self.config.gnews_api_key\n\n    def extract(self, query: str, from_date: str, to_date: str, **kwargs) -&gt; List[Dict[str, Any]]:\n        \"\"\"\n        Extrai not\u00edcias da GNews API.\n\n        Args:\n            query: Consulta para busca de not\u00edcias\n            from_date: Data inicial no formato YYYY-MM-DD\n            to_date: Data final no formato YYYY-MM-DD\n            **kwargs: Par\u00e2metros adicionais (language, country, max_results)\n\n        Returns:\n            List[Dict[str, Any]]: Lista de artigos extra\u00eddos\n        \"\"\"\n        language = kwargs.get(\"language\", \"pt\")\n        country = kwargs.get(\"country\", \"br\")\n        max_results = kwargs.get(\"max_results\", 20)\n\n        if not self.validate_source():\n            logger.error(\"API key inv\u00e1lida ou n\u00e3o configurada\")\n            return []\n\n        logger.info(f\"Buscando not\u00edcias da GNews de {from_date} at\u00e9 {to_date}...\")\n\n        try:\n            from_date_obj = datetime.strptime(from_date, \"%Y-%m-%d\")\n            from_timestamp = int(from_date_obj.timestamp())\n        except ValueError:\n            logger.error(f\"Formato de data inv\u00e1lido para from_date: {from_date}\")\n            return []\n\n        url = (\n            f\"https://gnews.io/api/v4/search?q={query}\"\n            f\"&amp;lang={language}&amp;country={country}&amp;max={max_results}\"\n            f\"&amp;from={from_date}T00:00:00Z&amp;to={to_date}T23:59:59Z\"\n            f\"&amp;apikey={self.api_key}\"\n        )\n\n        try:\n            response = requests.get(url)\n            response.raise_for_status()\n            data = response.json()\n\n            articles = data.get(\"articles\", [])\n\n            standardized_articles = []\n            for article in articles:\n                standardized_article = {\n                    \"title\": article.get(\"title\"),\n                    \"description\": article.get(\"description\"),\n                    \"content\": article.get(\"content\"),\n                    \"url\": article.get(\"url\"),\n                    \"publishedAt\": article.get(\"publishedAt\"),\n                    \"source\": {\n                        \"name\": article.get(\"source\", {}).get(\"name\"),\n                        \"url\": article.get(\"source\", {}).get(\"url\")\n                    },\n                    \"_source\": \"gnews\"\n                }\n                standardized_articles.append(standardized_article)\n\n            logger.info(f\"{len(standardized_articles)} artigos encontrados na GNews de {from_date} at\u00e9 {to_date}\")\n            return standardized_articles\n\n        except Exception as e:\n            logger.error(f\"Erro na extra\u00e7\u00e3o da GNews para o per\u00edodo {from_date} a {to_date}: {e}\")\n            return []\n\n    def validate_source(self) -&gt; bool:\n        \"\"\"\n        Valida se a chave da API est\u00e1 configurada.\n\n        Returns:\n            bool: True se a chave for v\u00e1lida, False caso contr\u00e1rio\n        \"\"\"\n        return bool(self.api_key)\n\n    def get_source_name(self) -&gt; str:\n        \"\"\"\n        Retorna o nome da fonte.\n\n        Returns:\n            str: Nome da fonte\n        \"\"\"\n        return \"GNews\" \n</code></pre>"},{"location":"src/extractors/#src.etl.extractors.base_extractor.BaseExtractor.extract","title":"<code>extract(query, from_date, to_date, **kwargs)</code>  <code>abstractmethod</code>","text":"<p>M\u00e9todo para extrair dados de uma fonte.</p> <p>Parameters:</p> Name Type Description Default <code>query</code> <code>str</code> <p>Consulta para busca de not\u00edcias</p> required <code>from_date</code> <code>str</code> <p>Data inicial no formato YYYY-MM-DD</p> required <code>to_date</code> <code>str</code> <p>Data final no formato YYYY-MM-DD</p> required <code>**kwargs</code> <p>Par\u00e2metros espec\u00edficos para a extra\u00e7\u00e3o</p> <code>{}</code> <p>Returns:</p> Type Description <code>List[Dict[str, Any]]</code> <p>List[Dict[str, Any]]: Lista de artigos extra\u00eddos</p> Source code in <code>src\\etl\\extractors\\base_extractor.py</code> <pre><code>@abstractmethod\ndef extract(self, query: str, from_date: str, to_date: str, **kwargs) -&gt; List[Dict[str, Any]]:\n    \"\"\"\n    M\u00e9todo para extrair dados de uma fonte.\n\n    Args:\n        query: Consulta para busca de not\u00edcias\n        from_date: Data inicial no formato YYYY-MM-DD\n        to_date: Data final no formato YYYY-MM-DD\n        **kwargs: Par\u00e2metros espec\u00edficos para a extra\u00e7\u00e3o\n\n    Returns:\n        List[Dict[str, Any]]: Lista de artigos extra\u00eddos\n    \"\"\"\n    pass\n</code></pre>"},{"location":"src/extractors/#src.etl.extractors.base_extractor.BaseExtractor.get_source_name","title":"<code>get_source_name()</code>  <code>abstractmethod</code>","text":"<p>Retorna o nome da fonte de dados.</p> <p>Returns:</p> Name Type Description <code>str</code> <code>str</code> <p>Nome da fonte</p> Source code in <code>src\\etl\\extractors\\base_extractor.py</code> <pre><code>@abstractmethod\ndef get_source_name(self) -&gt; str:\n    \"\"\"\n    Retorna o nome da fonte de dados.\n\n    Returns:\n        str: Nome da fonte\n    \"\"\"\n    pass \n</code></pre>"},{"location":"src/extractors/#src.etl.extractors.base_extractor.BaseExtractor.validate_source","title":"<code>validate_source()</code>  <code>abstractmethod</code>","text":"<p>M\u00e9todo para validar a disponibilidade e autenticidade da fonte.</p> <p>Returns:</p> Name Type Description <code>bool</code> <code>bool</code> <p>True se a fonte for v\u00e1lida, False caso contr\u00e1rio</p> Source code in <code>src\\etl\\extractors\\base_extractor.py</code> <pre><code>@abstractmethod\ndef validate_source(self) -&gt; bool:\n    \"\"\"\n    M\u00e9todo para validar a disponibilidade e autenticidade da fonte.\n\n    Returns:\n        bool: True se a fonte for v\u00e1lida, False caso contr\u00e1rio\n    \"\"\"\n    pass\n</code></pre>"},{"location":"src/extractors/#src.etl.extractors.news_api_extractor.NewsAPIExtractor.__init__","title":"<code>__init__(api_key=None)</code>","text":"<p>Inicializa o extrator com a chave da API.</p> <p>Parameters:</p> Name Type Description Default <code>api_key</code> <code>Optional[str]</code> <p>Chave da API News API (opcional)</p> <code>None</code> Source code in <code>src\\etl\\extractors\\news_api_extractor.py</code> <pre><code>def __init__(self, api_key: Optional[str] = None):\n    \"\"\"\n    Inicializa o extrator com a chave da API.\n\n    Args:\n        api_key: Chave da API News API (opcional)\n    \"\"\"\n    self.config = Config()\n    self.api_key = api_key or self.config.news_api_key\n</code></pre>"},{"location":"src/extractors/#src.etl.extractors.news_api_extractor.NewsAPIExtractor.extract","title":"<code>extract(query, from_date, to_date, **kwargs)</code>","text":"<p>Extrai not\u00edcias da News API.</p> <p>Parameters:</p> Name Type Description Default <code>query</code> <code>str</code> <p>Consulta para busca de not\u00edcias</p> required <code>from_date</code> <code>str</code> <p>Data inicial no formato YYYY-MM-DD</p> required <code>to_date</code> <code>str</code> <p>Data final no formato YYYY-MM-DD</p> required <code>**kwargs</code> <p>Par\u00e2metros adicionais (language, page_size)</p> <code>{}</code> <p>Returns:</p> Type Description <code>List[Dict[str, Any]]</code> <p>List[Dict[str, Any]]: Lista de artigos extra\u00eddos</p> Source code in <code>src\\etl\\extractors\\news_api_extractor.py</code> <pre><code>def extract(self, query: str, from_date: str, to_date: str, **kwargs) -&gt; List[Dict[str, Any]]:\n    \"\"\"\n    Extrai not\u00edcias da News API.\n\n    Args:\n        query: Consulta para busca de not\u00edcias\n        from_date: Data inicial no formato YYYY-MM-DD\n        to_date: Data final no formato YYYY-MM-DD\n        **kwargs: Par\u00e2metros adicionais (language, page_size)\n\n    Returns:\n        List[Dict[str, Any]]: Lista de artigos extra\u00eddos\n    \"\"\"\n    language = kwargs.get(\"language\", \"pt\")\n    page_size = kwargs.get(\"page_size\", 50)\n\n    if not self.validate_source():\n        logger.error(\"API key inv\u00e1lida ou n\u00e3o configurada\")\n        return []\n\n    logger.info(f\"Buscando not\u00edcias da NewsAPI de {from_date} at\u00e9 {to_date}...\")\n\n    url = (\n        f\"https://newsapi.org/v2/everything?q={query}\"\n        f\"&amp;language={language}&amp;pageSize={page_size}&amp;page=1\"\n        f\"&amp;from={from_date}&amp;to={to_date}&amp;sortBy=relevancy&amp;apiKey={self.api_key}\"\n    )\n    headers = {\"User-Agent\": \"Mozilla/5.0\"}\n\n    try:\n        response = requests.get(url, headers=headers)\n        response.raise_for_status()\n        data = response.json()\n        articles = data.get(\"articles\", [])\n\n        for article in articles:\n            article[\"_source\"] = \"newsapi\"\n\n        logger.info(f\"{len(articles)} artigos encontrados de {from_date} at\u00e9 {to_date}\")\n        return articles\n\n    except Exception as e:\n        logger.error(f\"Erro na extra\u00e7\u00e3o da NewsAPI para o per\u00edodo {from_date} a {to_date}: {e}\")\n        return []\n</code></pre>"},{"location":"src/extractors/#src.etl.extractors.news_api_extractor.NewsAPIExtractor.get_source_name","title":"<code>get_source_name()</code>","text":"<p>Retorna o nome da fonte.</p> <p>Returns:</p> Name Type Description <code>str</code> <code>str</code> <p>Nome da fonte</p> Source code in <code>src\\etl\\extractors\\news_api_extractor.py</code> <pre><code>def get_source_name(self) -&gt; str:\n    \"\"\"\n    Retorna o nome da fonte.\n\n    Returns:\n        str: Nome da fonte\n    \"\"\"\n    return \"NewsAPI\" \n</code></pre>"},{"location":"src/extractors/#src.etl.extractors.news_api_extractor.NewsAPIExtractor.validate_source","title":"<code>validate_source()</code>","text":"<p>Valida se a chave da API est\u00e1 configurada.</p> <p>Returns:</p> Name Type Description <code>bool</code> <code>bool</code> <p>True se a chave for v\u00e1lida, False caso contr\u00e1rio</p> Source code in <code>src\\etl\\extractors\\news_api_extractor.py</code> <pre><code>def validate_source(self) -&gt; bool:\n    \"\"\"\n    Valida se a chave da API est\u00e1 configurada.\n\n    Returns:\n        bool: True se a chave for v\u00e1lida, False caso contr\u00e1rio\n    \"\"\"\n    return bool(self.api_key)\n</code></pre>"},{"location":"src/extractors/#src.etl.extractors.gnews_extractor.GNewsExtractor.__init__","title":"<code>__init__(api_key=None)</code>","text":"<p>Inicializa o extrator com a chave da API.</p> <p>Parameters:</p> Name Type Description Default <code>api_key</code> <code>Optional[str]</code> <p>Chave da API GNews (opcional)</p> <code>None</code> Source code in <code>src\\etl\\extractors\\gnews_extractor.py</code> <pre><code>def __init__(self, api_key: Optional[str] = None):\n    \"\"\"\n    Inicializa o extrator com a chave da API.\n\n    Args:\n        api_key: Chave da API GNews (opcional)\n    \"\"\"\n    self.config = Config()\n    self.api_key = api_key or self.config.gnews_api_key\n</code></pre>"},{"location":"src/extractors/#src.etl.extractors.gnews_extractor.GNewsExtractor.extract","title":"<code>extract(query, from_date, to_date, **kwargs)</code>","text":"<p>Extrai not\u00edcias da GNews API.</p> <p>Parameters:</p> Name Type Description Default <code>query</code> <code>str</code> <p>Consulta para busca de not\u00edcias</p> required <code>from_date</code> <code>str</code> <p>Data inicial no formato YYYY-MM-DD</p> required <code>to_date</code> <code>str</code> <p>Data final no formato YYYY-MM-DD</p> required <code>**kwargs</code> <p>Par\u00e2metros adicionais (language, country, max_results)</p> <code>{}</code> <p>Returns:</p> Type Description <code>List[Dict[str, Any]]</code> <p>List[Dict[str, Any]]: Lista de artigos extra\u00eddos</p> Source code in <code>src\\etl\\extractors\\gnews_extractor.py</code> <pre><code>def extract(self, query: str, from_date: str, to_date: str, **kwargs) -&gt; List[Dict[str, Any]]:\n    \"\"\"\n    Extrai not\u00edcias da GNews API.\n\n    Args:\n        query: Consulta para busca de not\u00edcias\n        from_date: Data inicial no formato YYYY-MM-DD\n        to_date: Data final no formato YYYY-MM-DD\n        **kwargs: Par\u00e2metros adicionais (language, country, max_results)\n\n    Returns:\n        List[Dict[str, Any]]: Lista de artigos extra\u00eddos\n    \"\"\"\n    language = kwargs.get(\"language\", \"pt\")\n    country = kwargs.get(\"country\", \"br\")\n    max_results = kwargs.get(\"max_results\", 20)\n\n    if not self.validate_source():\n        logger.error(\"API key inv\u00e1lida ou n\u00e3o configurada\")\n        return []\n\n    logger.info(f\"Buscando not\u00edcias da GNews de {from_date} at\u00e9 {to_date}...\")\n\n    try:\n        from_date_obj = datetime.strptime(from_date, \"%Y-%m-%d\")\n        from_timestamp = int(from_date_obj.timestamp())\n    except ValueError:\n        logger.error(f\"Formato de data inv\u00e1lido para from_date: {from_date}\")\n        return []\n\n    url = (\n        f\"https://gnews.io/api/v4/search?q={query}\"\n        f\"&amp;lang={language}&amp;country={country}&amp;max={max_results}\"\n        f\"&amp;from={from_date}T00:00:00Z&amp;to={to_date}T23:59:59Z\"\n        f\"&amp;apikey={self.api_key}\"\n    )\n\n    try:\n        response = requests.get(url)\n        response.raise_for_status()\n        data = response.json()\n\n        articles = data.get(\"articles\", [])\n\n        standardized_articles = []\n        for article in articles:\n            standardized_article = {\n                \"title\": article.get(\"title\"),\n                \"description\": article.get(\"description\"),\n                \"content\": article.get(\"content\"),\n                \"url\": article.get(\"url\"),\n                \"publishedAt\": article.get(\"publishedAt\"),\n                \"source\": {\n                    \"name\": article.get(\"source\", {}).get(\"name\"),\n                    \"url\": article.get(\"source\", {}).get(\"url\")\n                },\n                \"_source\": \"gnews\"\n            }\n            standardized_articles.append(standardized_article)\n\n        logger.info(f\"{len(standardized_articles)} artigos encontrados na GNews de {from_date} at\u00e9 {to_date}\")\n        return standardized_articles\n\n    except Exception as e:\n        logger.error(f\"Erro na extra\u00e7\u00e3o da GNews para o per\u00edodo {from_date} a {to_date}: {e}\")\n        return []\n</code></pre>"},{"location":"src/extractors/#src.etl.extractors.gnews_extractor.GNewsExtractor.get_source_name","title":"<code>get_source_name()</code>","text":"<p>Retorna o nome da fonte.</p> <p>Returns:</p> Name Type Description <code>str</code> <code>str</code> <p>Nome da fonte</p> Source code in <code>src\\etl\\extractors\\gnews_extractor.py</code> <pre><code>def get_source_name(self) -&gt; str:\n    \"\"\"\n    Retorna o nome da fonte.\n\n    Returns:\n        str: Nome da fonte\n    \"\"\"\n    return \"GNews\" \n</code></pre>"},{"location":"src/extractors/#src.etl.extractors.gnews_extractor.GNewsExtractor.validate_source","title":"<code>validate_source()</code>","text":"<p>Valida se a chave da API est\u00e1 configurada.</p> <p>Returns:</p> Name Type Description <code>bool</code> <code>bool</code> <p>True se a chave for v\u00e1lida, False caso contr\u00e1rio</p> Source code in <code>src\\etl\\extractors\\gnews_extractor.py</code> <pre><code>def validate_source(self) -&gt; bool:\n    \"\"\"\n    Valida se a chave da API est\u00e1 configurada.\n\n    Returns:\n        bool: True se a chave for v\u00e1lida, False caso contr\u00e1rio\n    \"\"\"\n    return bool(self.api_key)\n</code></pre>"},{"location":"src/loaders/","title":"Documenta\u00e7\u00e3o da API de Carregadores","text":"<p>               Bases: <code>ABC</code></p> <p>Interface base para todos os carregadores de dados. Seguindo o princ\u00edpio da Interface Segregation (ISP) do SOLID.</p> Source code in <code>src\\etl\\loaders\\base_loader.py</code> <pre><code>class BaseLoader(ABC):\n    \"\"\"\n    Interface base para todos os carregadores de dados.\n    Seguindo o princ\u00edpio da Interface Segregation (ISP) do SOLID.\n    \"\"\"\n\n    @abstractmethod\n    def load(self, data: List[Dict[str, Any]], **kwargs) -&gt; bool:\n        \"\"\"\n        M\u00e9todo para carregar dados em um destino.\n\n        Args:\n            data: Lista de registros a serem carregados\n            **kwargs: Par\u00e2metros espec\u00edficos para o carregamento\n\n        Returns:\n            bool: True se o carregamento for bem-sucedido, False caso contr\u00e1rio\n        \"\"\"\n        pass\n\n    @abstractmethod\n    def validate_destination(self) -&gt; bool:\n        \"\"\"\n        M\u00e9todo para validar o destino dos dados.\n\n        Returns:\n            bool: True se o destino for v\u00e1lido, False caso contr\u00e1rio\n        \"\"\"\n        pass\n\n    @abstractmethod\n    def get_loader_name(self) -&gt; str:\n        \"\"\"\n        Retorna o nome do carregador.\n\n        Returns:\n            str: Nome do carregador\n        \"\"\"\n        pass \n</code></pre> <p>               Bases: <code>BaseLoader</code></p> <p>Carregador de dados para o PostgreSQL. Implementa a interface BaseLoader.</p> Source code in <code>src\\etl\\loaders\\postgres_loader.py</code> <pre><code>class PostgresLoader(BaseLoader):\n    \"\"\"\n    Carregador de dados para o PostgreSQL.\n    Implementa a interface BaseLoader.\n    \"\"\"\n\n    def __init__(self, table_name: Optional[str] = None):\n        \"\"\"\n        Inicializa o carregador com o nome da tabela padr\u00e3o.\n\n        Args:\n            table_name: Nome da tabela padr\u00e3o (opcional)\n        \"\"\"\n        self.db = Database()\n        self.default_table_name = table_name\n\n    def load(self, data: List[Dict[str, Any]], **kwargs) -&gt; bool:\n        \"\"\"\n        Carrega dados em uma tabela do PostgreSQL.\n\n        Args:\n            data: Lista de registros a serem carregados\n            **kwargs: Par\u00e2metros adicionais (table_name, if_exists, index)\n\n        Returns:\n            bool: True se o carregamento for bem-sucedido, False caso contr\u00e1rio\n        \"\"\"\n        if not data:\n            logger.warning(\"Nenhum dado para carregar no PostgreSQL\")\n            return False\n\n        if not self.validate_destination():\n            logger.error(\"Conex\u00e3o com PostgreSQL n\u00e3o dispon\u00edvel\")\n            return False\n\n        table_name = kwargs.get(\"table_name\", self.default_table_name)\n        if_exists = kwargs.get(\"if_exists\", \"replace\")\n        index = kwargs.get(\"index\", False)\n\n        if not table_name:\n            logger.error(\"Nome da tabela n\u00e3o especificado\")\n            return False\n\n        try:\n            df = pd.DataFrame(data)\n\n            for column in df.columns:\n                if df[column].dtype == 'object':\n                    if all(isinstance(x, dict) for x in df[column].dropna()):\n                        for key in data[0][column].keys():\n                            df[f\"{column}_{key}\"] = df[column].apply(\n                                lambda x: x.get(key) if isinstance(x, dict) else None\n                            )\n                        df = df.drop(column, axis=1)\n\n            result = self.db.dataframe_to_sql(\n                df, table_name, if_exists=if_exists, index=index\n            )\n\n            if result:\n                logger.info(f\"Carregados {len(df)} registros na tabela {table_name}\")\n            else:\n                logger.error(f\"Falha ao carregar dados na tabela {table_name}\")\n\n            return result\n\n        except Exception as e:\n            logger.error(f\"Erro ao carregar dados no PostgreSQL: {e}\")\n            return False\n\n    def validate_destination(self) -&gt; bool:\n        \"\"\"\n        Valida se a conex\u00e3o com o PostgreSQL est\u00e1 dispon\u00edvel.\n\n        Returns:\n            bool: True se o PostgreSQL estiver dispon\u00edvel, False caso contr\u00e1rio\n        \"\"\"\n        try:\n            self.db.execute_query(\"SELECT 1\")\n            return True\n        except Exception as e:\n            logger.error(f\"Erro ao validar conex\u00e3o com PostgreSQL: {e}\")\n            return False\n\n    def get_loader_name(self) -&gt; str:\n        \"\"\"\n        Retorna o nome do carregador.\n\n        Returns:\n            str: Nome do carregador\n        \"\"\"\n        return \"PostgresLoader\" \n</code></pre> <p>               Bases: <code>BaseLoader</code></p> <p>Carregador de dados para o Amazon S3. Implementa a interface BaseLoader.</p> Source code in <code>src\\etl\\loaders\\s3_uploader.py</code> <pre><code>class S3Uploader(BaseLoader):\n    \"\"\"\n    Carregador de dados para o Amazon S3.\n    Implementa a interface BaseLoader.\n    \"\"\"\n\n    def __init__(self, bucket_name: Optional[str] = None, region_name: Optional[str] = None):\n        \"\"\"\n        Inicializa o uploader com nome do bucket e regi\u00e3o.\n\n        Args:\n            bucket_name: Nome do bucket S3 (opcional)\n            region_name: Nome da regi\u00e3o AWS (opcional)\n        \"\"\"\n        self.config = Config()\n        self.bucket_name = bucket_name or self.config.s3_bucket\n        self.region_name = region_name or self.config.aws_region\n        self._s3_client = None\n\n    @property\n    def s3_client(self):\n        \"\"\"\n        Retorna cliente S3, criando um novo se n\u00e3o existir.\n\n        Returns:\n            boto3.client: Cliente S3\n        \"\"\"\n        if self._s3_client is None:\n            try:\n                self._s3_client = boto3.client(\n                    \"s3\",\n                    aws_access_key_id=self.config.aws_access_key,\n                    aws_secret_access_key=self.config.aws_secret_key,\n                    region_name=self.region_name\n                )\n            except Exception as e:\n                logger.error(f\"Erro ao criar cliente S3: {e}\")\n                raise\n        return self._s3_client\n\n    def load(self, data: List[Dict[str, Any]], **kwargs) -&gt; bool:\n        \"\"\"\n        Carrega dados no S3, salvando-os como arquivo JSON.\n\n        Args:\n            data: Lista de registros a serem carregados\n            **kwargs: Par\u00e2metros adicionais (object_name, content_type, metadata)\n\n        Returns:\n            bool: True se o carregamento for bem-sucedido, False caso contr\u00e1rio\n        \"\"\"\n        if not data:\n            logger.warning(\"Nenhum dado para carregar no S3\")\n            return False\n\n        if not self.validate_destination():\n            logger.error(\"AWS S3 n\u00e3o est\u00e1 configurado corretamente\")\n            return False\n\n        object_name = kwargs.get(\"object_name\")\n        content_type = kwargs.get(\"content_type\", \"application/json\")\n        metadata = kwargs.get(\"metadata\", {})\n\n        if not object_name:\n            from datetime import datetime\n            timestamp = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n            object_name = f\"news_data_{timestamp}.json\"\n\n        try:\n            with tempfile.NamedTemporaryFile(mode='w+', suffix='.json', delete=False) as tmp:\n                json.dump(data, tmp, ensure_ascii=False, indent=4)\n                tmp_filename = tmp.name\n\n            extra_args = {\n                \"ContentType\": content_type\n            }\n\n            if metadata:\n                extra_args[\"Metadata\"] = {\n                    str(k): str(v) for k, v in metadata.items()\n                }\n\n            self.s3_client.upload_file(\n                tmp_filename, \n                self.bucket_name, \n                object_name,\n                ExtraArgs=extra_args\n            )\n\n            os.unlink(tmp_filename)\n\n            logger.info(f\"Carregados {len(data)} registros no S3: {self.bucket_name}/{object_name}\")\n            return True\n\n        except Exception as e:\n            logger.error(f\"Erro ao carregar dados no S3: {e}\")\n\n            if 'tmp_filename' in locals():\n                try:\n                    os.unlink(tmp_filename)\n                except:\n                    pass\n\n            return False\n\n    def validate_destination(self) -&gt; bool:\n        \"\"\"\n        Valida se o bucket S3 existe e se temos acesso.\n\n        Returns:\n            bool: True se o bucket estiver acess\u00edvel, False caso contr\u00e1rio\n        \"\"\"\n        if not all([self.config.aws_access_key, self.config.aws_secret_key, self.bucket_name]):\n            logger.error(\"Credenciais AWS ou nome do bucket n\u00e3o configurados\")\n            return False\n\n        try:\n            self.s3_client.head_bucket(Bucket=self.bucket_name)\n            return True\n        except ClientError as e:\n            error_code = e.response['Error']['Code']\n            if error_code == '404':\n                logger.error(f\"O bucket '{self.bucket_name}' n\u00e3o existe\")\n            elif error_code == '403':\n                logger.error(f\"Sem permiss\u00e3o para acessar o bucket '{self.bucket_name}'\")\n            else:\n                logger.error(f\"Erro ao validar bucket S3: {e}\")\n            return False\n        except Exception as e:\n            logger.error(f\"Erro ao validar conex\u00e3o com S3: {e}\")\n            return False\n\n    def get_loader_name(self) -&gt; str:\n        \"\"\"\n        Retorna o nome do carregador.\n\n        Returns:\n            str: Nome do carregador\n        \"\"\"\n        return \"S3Uploader\" \n</code></pre>"},{"location":"src/loaders/#src.etl.loaders.base_loader.BaseLoader.get_loader_name","title":"<code>get_loader_name()</code>  <code>abstractmethod</code>","text":"<p>Retorna o nome do carregador.</p> <p>Returns:</p> Name Type Description <code>str</code> <code>str</code> <p>Nome do carregador</p> Source code in <code>src\\etl\\loaders\\base_loader.py</code> <pre><code>@abstractmethod\ndef get_loader_name(self) -&gt; str:\n    \"\"\"\n    Retorna o nome do carregador.\n\n    Returns:\n        str: Nome do carregador\n    \"\"\"\n    pass \n</code></pre>"},{"location":"src/loaders/#src.etl.loaders.base_loader.BaseLoader.load","title":"<code>load(data, **kwargs)</code>  <code>abstractmethod</code>","text":"<p>M\u00e9todo para carregar dados em um destino.</p> <p>Parameters:</p> Name Type Description Default <code>data</code> <code>List[Dict[str, Any]]</code> <p>Lista de registros a serem carregados</p> required <code>**kwargs</code> <p>Par\u00e2metros espec\u00edficos para o carregamento</p> <code>{}</code> <p>Returns:</p> Name Type Description <code>bool</code> <code>bool</code> <p>True se o carregamento for bem-sucedido, False caso contr\u00e1rio</p> Source code in <code>src\\etl\\loaders\\base_loader.py</code> <pre><code>@abstractmethod\ndef load(self, data: List[Dict[str, Any]], **kwargs) -&gt; bool:\n    \"\"\"\n    M\u00e9todo para carregar dados em um destino.\n\n    Args:\n        data: Lista de registros a serem carregados\n        **kwargs: Par\u00e2metros espec\u00edficos para o carregamento\n\n    Returns:\n        bool: True se o carregamento for bem-sucedido, False caso contr\u00e1rio\n    \"\"\"\n    pass\n</code></pre>"},{"location":"src/loaders/#src.etl.loaders.base_loader.BaseLoader.validate_destination","title":"<code>validate_destination()</code>  <code>abstractmethod</code>","text":"<p>M\u00e9todo para validar o destino dos dados.</p> <p>Returns:</p> Name Type Description <code>bool</code> <code>bool</code> <p>True se o destino for v\u00e1lido, False caso contr\u00e1rio</p> Source code in <code>src\\etl\\loaders\\base_loader.py</code> <pre><code>@abstractmethod\ndef validate_destination(self) -&gt; bool:\n    \"\"\"\n    M\u00e9todo para validar o destino dos dados.\n\n    Returns:\n        bool: True se o destino for v\u00e1lido, False caso contr\u00e1rio\n    \"\"\"\n    pass\n</code></pre>"},{"location":"src/loaders/#src.etl.loaders.postgres_loader.PostgresLoader.__init__","title":"<code>__init__(table_name=None)</code>","text":"<p>Inicializa o carregador com o nome da tabela padr\u00e3o.</p> <p>Parameters:</p> Name Type Description Default <code>table_name</code> <code>Optional[str]</code> <p>Nome da tabela padr\u00e3o (opcional)</p> <code>None</code> Source code in <code>src\\etl\\loaders\\postgres_loader.py</code> <pre><code>def __init__(self, table_name: Optional[str] = None):\n    \"\"\"\n    Inicializa o carregador com o nome da tabela padr\u00e3o.\n\n    Args:\n        table_name: Nome da tabela padr\u00e3o (opcional)\n    \"\"\"\n    self.db = Database()\n    self.default_table_name = table_name\n</code></pre>"},{"location":"src/loaders/#src.etl.loaders.postgres_loader.PostgresLoader.get_loader_name","title":"<code>get_loader_name()</code>","text":"<p>Retorna o nome do carregador.</p> <p>Returns:</p> Name Type Description <code>str</code> <code>str</code> <p>Nome do carregador</p> Source code in <code>src\\etl\\loaders\\postgres_loader.py</code> <pre><code>def get_loader_name(self) -&gt; str:\n    \"\"\"\n    Retorna o nome do carregador.\n\n    Returns:\n        str: Nome do carregador\n    \"\"\"\n    return \"PostgresLoader\" \n</code></pre>"},{"location":"src/loaders/#src.etl.loaders.postgres_loader.PostgresLoader.load","title":"<code>load(data, **kwargs)</code>","text":"<p>Carrega dados em uma tabela do PostgreSQL.</p> <p>Parameters:</p> Name Type Description Default <code>data</code> <code>List[Dict[str, Any]]</code> <p>Lista de registros a serem carregados</p> required <code>**kwargs</code> <p>Par\u00e2metros adicionais (table_name, if_exists, index)</p> <code>{}</code> <p>Returns:</p> Name Type Description <code>bool</code> <code>bool</code> <p>True se o carregamento for bem-sucedido, False caso contr\u00e1rio</p> Source code in <code>src\\etl\\loaders\\postgres_loader.py</code> <pre><code>def load(self, data: List[Dict[str, Any]], **kwargs) -&gt; bool:\n    \"\"\"\n    Carrega dados em uma tabela do PostgreSQL.\n\n    Args:\n        data: Lista de registros a serem carregados\n        **kwargs: Par\u00e2metros adicionais (table_name, if_exists, index)\n\n    Returns:\n        bool: True se o carregamento for bem-sucedido, False caso contr\u00e1rio\n    \"\"\"\n    if not data:\n        logger.warning(\"Nenhum dado para carregar no PostgreSQL\")\n        return False\n\n    if not self.validate_destination():\n        logger.error(\"Conex\u00e3o com PostgreSQL n\u00e3o dispon\u00edvel\")\n        return False\n\n    table_name = kwargs.get(\"table_name\", self.default_table_name)\n    if_exists = kwargs.get(\"if_exists\", \"replace\")\n    index = kwargs.get(\"index\", False)\n\n    if not table_name:\n        logger.error(\"Nome da tabela n\u00e3o especificado\")\n        return False\n\n    try:\n        df = pd.DataFrame(data)\n\n        for column in df.columns:\n            if df[column].dtype == 'object':\n                if all(isinstance(x, dict) for x in df[column].dropna()):\n                    for key in data[0][column].keys():\n                        df[f\"{column}_{key}\"] = df[column].apply(\n                            lambda x: x.get(key) if isinstance(x, dict) else None\n                        )\n                    df = df.drop(column, axis=1)\n\n        result = self.db.dataframe_to_sql(\n            df, table_name, if_exists=if_exists, index=index\n        )\n\n        if result:\n            logger.info(f\"Carregados {len(df)} registros na tabela {table_name}\")\n        else:\n            logger.error(f\"Falha ao carregar dados na tabela {table_name}\")\n\n        return result\n\n    except Exception as e:\n        logger.error(f\"Erro ao carregar dados no PostgreSQL: {e}\")\n        return False\n</code></pre>"},{"location":"src/loaders/#src.etl.loaders.postgres_loader.PostgresLoader.validate_destination","title":"<code>validate_destination()</code>","text":"<p>Valida se a conex\u00e3o com o PostgreSQL est\u00e1 dispon\u00edvel.</p> <p>Returns:</p> Name Type Description <code>bool</code> <code>bool</code> <p>True se o PostgreSQL estiver dispon\u00edvel, False caso contr\u00e1rio</p> Source code in <code>src\\etl\\loaders\\postgres_loader.py</code> <pre><code>def validate_destination(self) -&gt; bool:\n    \"\"\"\n    Valida se a conex\u00e3o com o PostgreSQL est\u00e1 dispon\u00edvel.\n\n    Returns:\n        bool: True se o PostgreSQL estiver dispon\u00edvel, False caso contr\u00e1rio\n    \"\"\"\n    try:\n        self.db.execute_query(\"SELECT 1\")\n        return True\n    except Exception as e:\n        logger.error(f\"Erro ao validar conex\u00e3o com PostgreSQL: {e}\")\n        return False\n</code></pre>"},{"location":"src/loaders/#src.etl.loaders.s3_uploader.S3Uploader.s3_client","title":"<code>s3_client</code>  <code>property</code>","text":"<p>Retorna cliente S3, criando um novo se n\u00e3o existir.</p> <p>Returns:</p> Type Description <p>boto3.client: Cliente S3</p>"},{"location":"src/loaders/#src.etl.loaders.s3_uploader.S3Uploader.__init__","title":"<code>__init__(bucket_name=None, region_name=None)</code>","text":"<p>Inicializa o uploader com nome do bucket e regi\u00e3o.</p> <p>Parameters:</p> Name Type Description Default <code>bucket_name</code> <code>Optional[str]</code> <p>Nome do bucket S3 (opcional)</p> <code>None</code> <code>region_name</code> <code>Optional[str]</code> <p>Nome da regi\u00e3o AWS (opcional)</p> <code>None</code> Source code in <code>src\\etl\\loaders\\s3_uploader.py</code> <pre><code>def __init__(self, bucket_name: Optional[str] = None, region_name: Optional[str] = None):\n    \"\"\"\n    Inicializa o uploader com nome do bucket e regi\u00e3o.\n\n    Args:\n        bucket_name: Nome do bucket S3 (opcional)\n        region_name: Nome da regi\u00e3o AWS (opcional)\n    \"\"\"\n    self.config = Config()\n    self.bucket_name = bucket_name or self.config.s3_bucket\n    self.region_name = region_name or self.config.aws_region\n    self._s3_client = None\n</code></pre>"},{"location":"src/loaders/#src.etl.loaders.s3_uploader.S3Uploader.get_loader_name","title":"<code>get_loader_name()</code>","text":"<p>Retorna o nome do carregador.</p> <p>Returns:</p> Name Type Description <code>str</code> <code>str</code> <p>Nome do carregador</p> Source code in <code>src\\etl\\loaders\\s3_uploader.py</code> <pre><code>def get_loader_name(self) -&gt; str:\n    \"\"\"\n    Retorna o nome do carregador.\n\n    Returns:\n        str: Nome do carregador\n    \"\"\"\n    return \"S3Uploader\" \n</code></pre>"},{"location":"src/loaders/#src.etl.loaders.s3_uploader.S3Uploader.load","title":"<code>load(data, **kwargs)</code>","text":"<p>Carrega dados no S3, salvando-os como arquivo JSON.</p> <p>Parameters:</p> Name Type Description Default <code>data</code> <code>List[Dict[str, Any]]</code> <p>Lista de registros a serem carregados</p> required <code>**kwargs</code> <p>Par\u00e2metros adicionais (object_name, content_type, metadata)</p> <code>{}</code> <p>Returns:</p> Name Type Description <code>bool</code> <code>bool</code> <p>True se o carregamento for bem-sucedido, False caso contr\u00e1rio</p> Source code in <code>src\\etl\\loaders\\s3_uploader.py</code> <pre><code>def load(self, data: List[Dict[str, Any]], **kwargs) -&gt; bool:\n    \"\"\"\n    Carrega dados no S3, salvando-os como arquivo JSON.\n\n    Args:\n        data: Lista de registros a serem carregados\n        **kwargs: Par\u00e2metros adicionais (object_name, content_type, metadata)\n\n    Returns:\n        bool: True se o carregamento for bem-sucedido, False caso contr\u00e1rio\n    \"\"\"\n    if not data:\n        logger.warning(\"Nenhum dado para carregar no S3\")\n        return False\n\n    if not self.validate_destination():\n        logger.error(\"AWS S3 n\u00e3o est\u00e1 configurado corretamente\")\n        return False\n\n    object_name = kwargs.get(\"object_name\")\n    content_type = kwargs.get(\"content_type\", \"application/json\")\n    metadata = kwargs.get(\"metadata\", {})\n\n    if not object_name:\n        from datetime import datetime\n        timestamp = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n        object_name = f\"news_data_{timestamp}.json\"\n\n    try:\n        with tempfile.NamedTemporaryFile(mode='w+', suffix='.json', delete=False) as tmp:\n            json.dump(data, tmp, ensure_ascii=False, indent=4)\n            tmp_filename = tmp.name\n\n        extra_args = {\n            \"ContentType\": content_type\n        }\n\n        if metadata:\n            extra_args[\"Metadata\"] = {\n                str(k): str(v) for k, v in metadata.items()\n            }\n\n        self.s3_client.upload_file(\n            tmp_filename, \n            self.bucket_name, \n            object_name,\n            ExtraArgs=extra_args\n        )\n\n        os.unlink(tmp_filename)\n\n        logger.info(f\"Carregados {len(data)} registros no S3: {self.bucket_name}/{object_name}\")\n        return True\n\n    except Exception as e:\n        logger.error(f\"Erro ao carregar dados no S3: {e}\")\n\n        if 'tmp_filename' in locals():\n            try:\n                os.unlink(tmp_filename)\n            except:\n                pass\n\n        return False\n</code></pre>"},{"location":"src/loaders/#src.etl.loaders.s3_uploader.S3Uploader.validate_destination","title":"<code>validate_destination()</code>","text":"<p>Valida se o bucket S3 existe e se temos acesso.</p> <p>Returns:</p> Name Type Description <code>bool</code> <code>bool</code> <p>True se o bucket estiver acess\u00edvel, False caso contr\u00e1rio</p> Source code in <code>src\\etl\\loaders\\s3_uploader.py</code> <pre><code>def validate_destination(self) -&gt; bool:\n    \"\"\"\n    Valida se o bucket S3 existe e se temos acesso.\n\n    Returns:\n        bool: True se o bucket estiver acess\u00edvel, False caso contr\u00e1rio\n    \"\"\"\n    if not all([self.config.aws_access_key, self.config.aws_secret_key, self.bucket_name]):\n        logger.error(\"Credenciais AWS ou nome do bucket n\u00e3o configurados\")\n        return False\n\n    try:\n        self.s3_client.head_bucket(Bucket=self.bucket_name)\n        return True\n    except ClientError as e:\n        error_code = e.response['Error']['Code']\n        if error_code == '404':\n            logger.error(f\"O bucket '{self.bucket_name}' n\u00e3o existe\")\n        elif error_code == '403':\n            logger.error(f\"Sem permiss\u00e3o para acessar o bucket '{self.bucket_name}'\")\n        else:\n            logger.error(f\"Erro ao validar bucket S3: {e}\")\n        return False\n    except Exception as e:\n        logger.error(f\"Erro ao validar conex\u00e3o com S3: {e}\")\n        return False\n</code></pre>"},{"location":"src/transformers/","title":"Documenta\u00e7\u00e3o da API de Transformadores","text":"<p>               Bases: <code>ABC</code></p> <p>Interface base para todos os transformadores de dados. Seguindo o princ\u00edpio da Interface Segregation (ISP) do SOLID.</p> Source code in <code>src\\etl\\transformers\\base_transformer.py</code> <pre><code>class BaseTransformer(ABC):\n    \"\"\"\n    Interface base para todos os transformadores de dados.\n    Seguindo o princ\u00edpio da Interface Segregation (ISP) do SOLID.\n    \"\"\"\n\n    @abstractmethod\n    def transform(self, data: List[Dict[str, Any]], **kwargs) -&gt; List[Dict[str, Any]]:\n        \"\"\"\n        M\u00e9todo para transformar dados.\n\n        Args:\n            data: Lista de registros a serem transformados\n            **kwargs: Par\u00e2metros espec\u00edficos para a transforma\u00e7\u00e3o\n\n        Returns:\n            List[Dict[str, Any]]: Lista de registros transformados\n        \"\"\"\n        pass\n\n    @abstractmethod\n    def validate(self, data: Dict[str, Any]) -&gt; bool:\n        \"\"\"\n        M\u00e9todo para validar um registro.\n\n        Args:\n            data: Registro a ser validado\n\n        Returns:\n            bool: True se o registro for v\u00e1lido, False caso contr\u00e1rio\n        \"\"\"\n        pass\n\n    @abstractmethod\n    def get_transformer_name(self) -&gt; str:\n        \"\"\"\n        Retorna o nome do transformador.\n\n        Returns:\n            str: Nome do transformador\n        \"\"\"\n        pass \n</code></pre> <p>               Bases: <code>BaseTransformer</code></p> <p>Transformador de not\u00edcias relacionadas a acidentes com \u00e1lcool. Implementa a interface BaseTransformer.</p> Source code in <code>src\\etl\\transformers\\news_transformer.py</code> <pre><code>class NewsTransformer(BaseTransformer):\n    \"\"\"\n    Transformador de not\u00edcias relacionadas a acidentes com \u00e1lcool.\n    Implementa a interface BaseTransformer.\n    \"\"\"\n\n    def __init__(self):\n        \"\"\"\n        Inicializa o transformador.\n        \"\"\"\n        pass\n\n    def transform(self, data: List[Dict[str, Any]], **kwargs) -&gt; List[Dict[str, Any]]:\n        \"\"\"\n        Transforma e filtra not\u00edcias relacionadas a acidentes com \u00e1lcool.\n\n        Args:\n            data: Lista de not\u00edcias a serem transformadas\n            **kwargs: Par\u00e2metros adicionais\n\n        Returns:\n            List[Dict[str, Any]]: Lista de not\u00edcias transformadas e filtradas\n        \"\"\"\n        filtered_news = []\n\n        if kwargs.get(\"deduplicate\", True):\n            data = self._deduplicate_articles(data)\n\n        for article in data:\n            content = f\"{article.get('title', '')} {article.get('description', '')} {article.get('content', '')}\"\n\n            if self._is_alcohol_accident(content):\n                relevance_score = self._calculate_relevance(content)\n\n                transformed_article = {\n                    \"title\": article.get(\"title\"),\n                    \"description\": article.get(\"description\"),\n                    \"url\": article.get(\"url\"),\n                    \"publishedAt\": article.get(\"publishedAt\"),\n                    \"relevance_score\": relevance_score,\n                    \"source\": article.get(\"source\", {}).get(\"name\") if isinstance(article.get(\"source\"), dict) else article.get(\"source\"),\n                    \"original_source\": article.get(\"_source\", \"unknown\")\n                }\n\n                filtered_news.append(transformed_article)\n\n        filtered_news.sort(key=lambda x: x.get(\"relevance_score\", 0), reverse=True)\n\n        logger.info(f\"Transformadas {len(filtered_news)} not\u00edcias relevantes de um total de {len(data)}\")\n        return filtered_news\n\n    def validate(self, data: Dict[str, Any]) -&gt; bool:\n        \"\"\"\n        Valida se um registro tem os campos m\u00ednimos necess\u00e1rios.\n\n        Args:\n            data: Registro a ser validado\n\n        Returns:\n            bool: True se o registro for v\u00e1lido, False caso contr\u00e1rio\n        \"\"\"\n        required_fields = [\"title\", \"url\"]\n        return all(field in data for field in required_fields)\n\n    def get_transformer_name(self) -&gt; str:\n        \"\"\"\n        Retorna o nome do transformador.\n\n        Returns:\n            str: Nome do transformador\n        \"\"\"\n        return \"NewsTransformer\"\n\n    def _normalize_text(self, text: str) -&gt; str:\n        \"\"\"\n        Normaliza o texto removendo acentos e convertendo para min\u00fasculas.\n\n        Args:\n            text: Texto a ser normalizado\n\n        Returns:\n            str: Texto normalizado\n        \"\"\"\n        if not text:\n            return \"\"\n        text = text.lower()\n        return \"\".join(\n            c for c in unicodedata.normalize(\"NFD\", text) \n            if unicodedata.category(c) != \"Mn\"\n        )\n\n    def _is_alcohol_accident(self, text: str) -&gt; bool:\n        \"\"\"\n        Verifica se o texto cont\u00e9m indica\u00e7\u00f5es de acidente relacionado a \u00e1lcool.\n\n        Args:\n            text: Texto a ser analisado\n\n        Returns:\n            bool: True se for um acidente relacionado a \u00e1lcool, False caso contr\u00e1rio\n        \"\"\"\n        text = text.lower()\n\n        keywords = [\n            r\"acidente.*(\u00e1lcool|alcool|bebida|embriagado|embriaguez)\",\n            r\"embriagado|embriaguez\",\n            r\"(dirigia|conduzia|ao volante).*(b\u00eabado|bebado|alcoolizado|embriagado)\",\n            r\"(motorista|condutor).*(b\u00eabado|bebado|alcoolizado|embriagado)\",\n            r\"sob (efeito|influ\u00eancia).*(\u00e1lcool|alcool|bebida)\",\n            r\"(teste|exame).*(alcoolemia|etil\u00f4metro|baf\u00f4metro)\",\n            r\"lei seca.*(acidente|colis\u00e3o|batida|capotamento|atropelamento)\",\n            r\"(\u00e1lcool|alcool|bebida).*(volante|dire\u00e7\u00e3o)\",\n            r\"(capotamento|colis\u00e3o|batida|acidente).*(\u00e1lcool|alcool|embriaguez)\",\n            r\"(v\u00edtima|vitima|morto|ferido).*(motorista|condutor).*(b\u00eabado|bebado|alcoolizado|embriagado)\",\n        ]\n\n        norm_text = self._normalize_text(text)\n        norm_keywords = [\n            r\"acidente.*(alcool|bebida|embriagado|embriaguez)\",\n            r\"embriagado|embriaguez\",\n            r\"(dirigia|conduzia|ao volante).*(bebado|alcoolizado|embriagado)\",\n            r\"(motorista|condutor).*(bebado|alcoolizado|embriagado)\",\n            r\"sob (efeito|influencia).*(alcool|bebida)\",\n            r\"(teste|exame).*(alcoolemia|etilometro|bafometro)\",\n            r\"lei seca.*(acidente|colisao|batida|capotamento|atropelamento)\",\n            r\"(alcool|bebida).*(volante|direcao)\",\n            r\"(capotamento|colisao|batida|acidente).*(alcool|embriaguez)\",\n            r\"(vitima|morto|ferido).*(motorista|condutor).*(bebado|alcoolizado|embriagado)\",\n        ]\n\n        return any(re.search(kw, text) for kw in keywords) or any(\n            re.search(kw, norm_text) for kw in norm_keywords\n        )\n\n    def _calculate_relevance(self, text: str) -&gt; int:\n        \"\"\"\n        Calcula um score de relev\u00e2ncia para o texto.\n\n        Args:\n            text: Texto para calcular relev\u00e2ncia\n\n        Returns:\n            int: Score de relev\u00e2ncia\n        \"\"\"\n        text = text.lower()\n        score = 0\n\n        primary_patterns = [\n            r\"(dirigia|conduzia|ao volante).*(b\u00eabado|bebado|alcoolizado|embriagado)\",\n            r\"(motorista|condutor).*(b\u00eabado|bebado|alcoolizado|embriagado)\",\n            r\"sob (efeito|influ\u00eancia) de (\u00e1lcool|alcool)\",\n            r\"(teste|exame).*(alcoolemia|etil\u00f4metro|baf\u00f4metro).*(positivo|acima)\",\n            r\"lei seca.*(infra\u00e7\u00e3o|infracao|autuado|detido)\",\n        ]\n\n        secondary_patterns = [\n            r\"(acidente|colis\u00e3o|batida).*(\u00e1lcool|alcool)\",\n            r\"lei seca\",\n            r\"(baf\u00f4metro|etil\u00f4metro)\",\n            r\"(embriagado|embriaguez)\",\n            r\"(v\u00edtima|vitima|morto|ferido).*(\u00e1lcool|alcool)\",\n        ]\n\n        tertiary_patterns = [\n            r\"acidente\",\n            r\"\u00e1lcool|alcool\",\n            r\"colis\u00e3o|batida\",\n            r\"motorista|condutor\",\n        ]\n\n        for pattern in primary_patterns:\n            if re.search(pattern, text):\n                score += 3\n\n        for pattern in secondary_patterns:\n            if re.search(pattern, text):\n                score += 2\n\n        for pattern in tertiary_patterns:\n            if re.search(pattern, text):\n                score += 1\n\n        return score\n\n    def _deduplicate_articles(self, articles: List[Dict[str, Any]]) -&gt; List[Dict[str, Any]]:\n        \"\"\"\n        Remove artigos duplicados baseados no t\u00edtulo ou URL.\n\n        Args:\n            articles: Lista de artigos a serem deduplicados\n\n        Returns:\n            List[Dict[str, Any]]: Lista de artigos \u00fanicos\n        \"\"\"\n        unique_articles = []\n        seen_titles: Set[str] = set()\n        seen_urls: Set[str] = set()\n\n        for article in articles:\n            title = self._normalize_text(article.get(\"title\", \"\"))\n            url = article.get(\"url\", \"\").strip()\n\n            if title and url and title not in seen_titles and url not in seen_urls:\n                seen_titles.add(title)\n                seen_urls.add(url)\n                unique_articles.append(article)\n\n        logger.info(f\"Deduplicados {len(articles) - len(unique_articles)} artigos duplicados\")\n        return unique_articles \n</code></pre>"},{"location":"src/transformers/#src.etl.transformers.base_transformer.BaseTransformer.get_transformer_name","title":"<code>get_transformer_name()</code>  <code>abstractmethod</code>","text":"<p>Retorna o nome do transformador.</p> <p>Returns:</p> Name Type Description <code>str</code> <code>str</code> <p>Nome do transformador</p> Source code in <code>src\\etl\\transformers\\base_transformer.py</code> <pre><code>@abstractmethod\ndef get_transformer_name(self) -&gt; str:\n    \"\"\"\n    Retorna o nome do transformador.\n\n    Returns:\n        str: Nome do transformador\n    \"\"\"\n    pass \n</code></pre>"},{"location":"src/transformers/#src.etl.transformers.base_transformer.BaseTransformer.transform","title":"<code>transform(data, **kwargs)</code>  <code>abstractmethod</code>","text":"<p>M\u00e9todo para transformar dados.</p> <p>Parameters:</p> Name Type Description Default <code>data</code> <code>List[Dict[str, Any]]</code> <p>Lista de registros a serem transformados</p> required <code>**kwargs</code> <p>Par\u00e2metros espec\u00edficos para a transforma\u00e7\u00e3o</p> <code>{}</code> <p>Returns:</p> Type Description <code>List[Dict[str, Any]]</code> <p>List[Dict[str, Any]]: Lista de registros transformados</p> Source code in <code>src\\etl\\transformers\\base_transformer.py</code> <pre><code>@abstractmethod\ndef transform(self, data: List[Dict[str, Any]], **kwargs) -&gt; List[Dict[str, Any]]:\n    \"\"\"\n    M\u00e9todo para transformar dados.\n\n    Args:\n        data: Lista de registros a serem transformados\n        **kwargs: Par\u00e2metros espec\u00edficos para a transforma\u00e7\u00e3o\n\n    Returns:\n        List[Dict[str, Any]]: Lista de registros transformados\n    \"\"\"\n    pass\n</code></pre>"},{"location":"src/transformers/#src.etl.transformers.base_transformer.BaseTransformer.validate","title":"<code>validate(data)</code>  <code>abstractmethod</code>","text":"<p>M\u00e9todo para validar um registro.</p> <p>Parameters:</p> Name Type Description Default <code>data</code> <code>Dict[str, Any]</code> <p>Registro a ser validado</p> required <p>Returns:</p> Name Type Description <code>bool</code> <code>bool</code> <p>True se o registro for v\u00e1lido, False caso contr\u00e1rio</p> Source code in <code>src\\etl\\transformers\\base_transformer.py</code> <pre><code>@abstractmethod\ndef validate(self, data: Dict[str, Any]) -&gt; bool:\n    \"\"\"\n    M\u00e9todo para validar um registro.\n\n    Args:\n        data: Registro a ser validado\n\n    Returns:\n        bool: True se o registro for v\u00e1lido, False caso contr\u00e1rio\n    \"\"\"\n    pass\n</code></pre>"},{"location":"src/transformers/#src.etl.transformers.news_transformer.NewsTransformer.__init__","title":"<code>__init__()</code>","text":"<p>Inicializa o transformador.</p> Source code in <code>src\\etl\\transformers\\news_transformer.py</code> <pre><code>def __init__(self):\n    \"\"\"\n    Inicializa o transformador.\n    \"\"\"\n    pass\n</code></pre>"},{"location":"src/transformers/#src.etl.transformers.news_transformer.NewsTransformer.get_transformer_name","title":"<code>get_transformer_name()</code>","text":"<p>Retorna o nome do transformador.</p> <p>Returns:</p> Name Type Description <code>str</code> <code>str</code> <p>Nome do transformador</p> Source code in <code>src\\etl\\transformers\\news_transformer.py</code> <pre><code>def get_transformer_name(self) -&gt; str:\n    \"\"\"\n    Retorna o nome do transformador.\n\n    Returns:\n        str: Nome do transformador\n    \"\"\"\n    return \"NewsTransformer\"\n</code></pre>"},{"location":"src/transformers/#src.etl.transformers.news_transformer.NewsTransformer.transform","title":"<code>transform(data, **kwargs)</code>","text":"<p>Transforma e filtra not\u00edcias relacionadas a acidentes com \u00e1lcool.</p> <p>Parameters:</p> Name Type Description Default <code>data</code> <code>List[Dict[str, Any]]</code> <p>Lista de not\u00edcias a serem transformadas</p> required <code>**kwargs</code> <p>Par\u00e2metros adicionais</p> <code>{}</code> <p>Returns:</p> Type Description <code>List[Dict[str, Any]]</code> <p>List[Dict[str, Any]]: Lista de not\u00edcias transformadas e filtradas</p> Source code in <code>src\\etl\\transformers\\news_transformer.py</code> <pre><code>def transform(self, data: List[Dict[str, Any]], **kwargs) -&gt; List[Dict[str, Any]]:\n    \"\"\"\n    Transforma e filtra not\u00edcias relacionadas a acidentes com \u00e1lcool.\n\n    Args:\n        data: Lista de not\u00edcias a serem transformadas\n        **kwargs: Par\u00e2metros adicionais\n\n    Returns:\n        List[Dict[str, Any]]: Lista de not\u00edcias transformadas e filtradas\n    \"\"\"\n    filtered_news = []\n\n    if kwargs.get(\"deduplicate\", True):\n        data = self._deduplicate_articles(data)\n\n    for article in data:\n        content = f\"{article.get('title', '')} {article.get('description', '')} {article.get('content', '')}\"\n\n        if self._is_alcohol_accident(content):\n            relevance_score = self._calculate_relevance(content)\n\n            transformed_article = {\n                \"title\": article.get(\"title\"),\n                \"description\": article.get(\"description\"),\n                \"url\": article.get(\"url\"),\n                \"publishedAt\": article.get(\"publishedAt\"),\n                \"relevance_score\": relevance_score,\n                \"source\": article.get(\"source\", {}).get(\"name\") if isinstance(article.get(\"source\"), dict) else article.get(\"source\"),\n                \"original_source\": article.get(\"_source\", \"unknown\")\n            }\n\n            filtered_news.append(transformed_article)\n\n    filtered_news.sort(key=lambda x: x.get(\"relevance_score\", 0), reverse=True)\n\n    logger.info(f\"Transformadas {len(filtered_news)} not\u00edcias relevantes de um total de {len(data)}\")\n    return filtered_news\n</code></pre>"},{"location":"src/transformers/#src.etl.transformers.news_transformer.NewsTransformer.validate","title":"<code>validate(data)</code>","text":"<p>Valida se um registro tem os campos m\u00ednimos necess\u00e1rios.</p> <p>Parameters:</p> Name Type Description Default <code>data</code> <code>Dict[str, Any]</code> <p>Registro a ser validado</p> required <p>Returns:</p> Name Type Description <code>bool</code> <code>bool</code> <p>True se o registro for v\u00e1lido, False caso contr\u00e1rio</p> Source code in <code>src\\etl\\transformers\\news_transformer.py</code> <pre><code>def validate(self, data: Dict[str, Any]) -&gt; bool:\n    \"\"\"\n    Valida se um registro tem os campos m\u00ednimos necess\u00e1rios.\n\n    Args:\n        data: Registro a ser validado\n\n    Returns:\n        bool: True se o registro for v\u00e1lido, False caso contr\u00e1rio\n    \"\"\"\n    required_fields = [\"title\", \"url\"]\n    return all(field in data for field in required_fields)\n</code></pre>"},{"location":"src/utils/","title":"Documenta\u00e7\u00e3o da API de Utilit\u00e1rios","text":"<p>Classe de configura\u00e7\u00e3o centralizada para toda a aplica\u00e7\u00e3o. Segue o padr\u00e3o Singleton para garantir uma \u00fanica inst\u00e2ncia.</p> Source code in <code>src\\utils\\config.py</code> <pre><code>class Config:\n    \"\"\"\n    Classe de configura\u00e7\u00e3o centralizada para toda a aplica\u00e7\u00e3o.\n    Segue o padr\u00e3o Singleton para garantir uma \u00fanica inst\u00e2ncia.\n    \"\"\"\n\n    _instance = None\n\n    def __new__(cls):\n        if cls._instance is None:\n            cls._instance = super(Config, cls).__new__(cls)\n            cls._instance._initialized = False\n        return cls._instance\n\n    def __init__(self):\n        if self._initialized:\n            return\n\n        load_dotenv()\n\n        self.base_dir = Path(__file__).resolve().parent.parent.parent\n        self.data_dir = self.base_dir / \"data\"\n        self.raw_data_dir = self.data_dir / \"raw\"\n        self.processed_data_dir = self.data_dir / \"processed\"\n\n        self.raw_data_dir.mkdir(parents=True, exist_ok=True)\n        self.processed_data_dir.mkdir(parents=True, exist_ok=True)\n\n        self.news_api_key = os.getenv(\"NEWS_API_KEY\")\n        self.gnews_api_key = os.getenv(\"GNEWS_API_KEY\")\n        self.newsdata_api_key = os.getenv(\"NEWSDATA_API_KEY\")\n\n        self.postgres_user = os.getenv(\"POSTGRES_USER\")\n        self.postgres_password = os.getenv(\"POSTGRES_PASSWORD\")\n        self.postgres_host = os.getenv(\"POSTGRES_HOST\", \"localhost\")\n        self.postgres_port = os.getenv(\"POSTGRES_PORT\", \"5432\")\n        self.postgres_db = os.getenv(\"POSTGRES_DB\", \"airflow\")\n\n        self.aws_access_key = os.getenv(\"AWS_ACCESS_KEY\")\n        self.aws_secret_key = os.getenv(\"AWS_SECRET_KEY\")\n        self.s3_bucket = os.getenv(\"S3_BUCKET\")\n        self.aws_region = os.getenv(\"AWS_REGION\", \"us-east-1\")\n\n        self._initialized = True\n\n    def get_postgres_conn_string(self) -&gt; str:\n        \"\"\"\n        Retorna a string de conex\u00e3o para o PostgreSQL.\n\n        Returns:\n            str: String de conex\u00e3o PostgreSQL\n        \"\"\"\n        return f\"postgresql+psycopg2://{self.postgres_user}:{self.postgres_password}@{self.postgres_host}:{self.postgres_port}/{self.postgres_db}\"\n\n    def get_api_key(self, api_name: str) -&gt; Optional[str]:\n        \"\"\"\n        Retorna a chave de API espec\u00edfica.\n\n        Args:\n            api_name: Nome da API ('newsapi', 'gnews', 'newsdata')\n\n        Returns:\n            Optional[str]: Chave da API ou None se n\u00e3o encontrada\n        \"\"\"\n        api_keys = {\n            \"newsapi\": self.news_api_key,\n            \"gnews\": self.gnews_api_key,\n            \"newsdata\": self.newsdata_api_key\n        }\n        return api_keys.get(api_name.lower())\n\n    def validate_required_env(self, keys: list) -&gt; bool:\n        \"\"\"\n        Valida se as vari\u00e1veis de ambiente necess\u00e1rias est\u00e3o configuradas.\n\n        Args:\n            keys: Lista de chaves de ambiente a serem validadas\n\n        Returns:\n            bool: True se todas as chaves existirem, False caso contr\u00e1rio\n        \"\"\"\n        for key in keys:\n            value = getattr(self, key, None)\n            if not value:\n                return False\n        return True \n</code></pre>"},{"location":"src/utils/#src.utils.config.Config.get_api_key","title":"<code>get_api_key(api_name)</code>","text":"<p>Retorna a chave de API espec\u00edfica.</p> <p>Parameters:</p> Name Type Description Default <code>api_name</code> <code>str</code> <p>Nome da API ('newsapi', 'gnews', 'newsdata')</p> required <p>Returns:</p> Type Description <code>Optional[str]</code> <p>Optional[str]: Chave da API ou None se n\u00e3o encontrada</p> Source code in <code>src\\utils\\config.py</code> <pre><code>def get_api_key(self, api_name: str) -&gt; Optional[str]:\n    \"\"\"\n    Retorna a chave de API espec\u00edfica.\n\n    Args:\n        api_name: Nome da API ('newsapi', 'gnews', 'newsdata')\n\n    Returns:\n        Optional[str]: Chave da API ou None se n\u00e3o encontrada\n    \"\"\"\n    api_keys = {\n        \"newsapi\": self.news_api_key,\n        \"gnews\": self.gnews_api_key,\n        \"newsdata\": self.newsdata_api_key\n    }\n    return api_keys.get(api_name.lower())\n</code></pre>"},{"location":"src/utils/#src.utils.config.Config.get_postgres_conn_string","title":"<code>get_postgres_conn_string()</code>","text":"<p>Retorna a string de conex\u00e3o para o PostgreSQL.</p> <p>Returns:</p> Name Type Description <code>str</code> <code>str</code> <p>String de conex\u00e3o PostgreSQL</p> Source code in <code>src\\utils\\config.py</code> <pre><code>def get_postgres_conn_string(self) -&gt; str:\n    \"\"\"\n    Retorna a string de conex\u00e3o para o PostgreSQL.\n\n    Returns:\n        str: String de conex\u00e3o PostgreSQL\n    \"\"\"\n    return f\"postgresql+psycopg2://{self.postgres_user}:{self.postgres_password}@{self.postgres_host}:{self.postgres_port}/{self.postgres_db}\"\n</code></pre>"},{"location":"src/utils/#src.utils.config.Config.validate_required_env","title":"<code>validate_required_env(keys)</code>","text":"<p>Valida se as vari\u00e1veis de ambiente necess\u00e1rias est\u00e3o configuradas.</p> <p>Parameters:</p> Name Type Description Default <code>keys</code> <code>list</code> <p>Lista de chaves de ambiente a serem validadas</p> required <p>Returns:</p> Name Type Description <code>bool</code> <code>bool</code> <p>True se todas as chaves existirem, False caso contr\u00e1rio</p> Source code in <code>src\\utils\\config.py</code> <pre><code>def validate_required_env(self, keys: list) -&gt; bool:\n    \"\"\"\n    Valida se as vari\u00e1veis de ambiente necess\u00e1rias est\u00e3o configuradas.\n\n    Args:\n        keys: Lista de chaves de ambiente a serem validadas\n\n    Returns:\n        bool: True se todas as chaves existirem, False caso contr\u00e1rio\n    \"\"\"\n    for key in keys:\n        value = getattr(self, key, None)\n        if not value:\n            return False\n    return True \n</code></pre>"},{"location":"src/utils/#src.utils.logger.setup_logger","title":"<code>setup_logger(name, log_level='INFO')</code>","text":"<p>Configura e retorna um logger formatado.</p> <p>Parameters:</p> Name Type Description Default <code>name</code> <code>str</code> <p>Nome do logger</p> required <code>log_level</code> <code>str</code> <p>N\u00edvel de log (DEBUG, INFO, WARNING, ERROR, CRITICAL)</p> <code>'INFO'</code> <p>Returns:</p> Type Description <code>Logger</code> <p>logging.Logger: Logger configurado</p> Source code in <code>src\\utils\\logger.py</code> <pre><code>def setup_logger(name: str, log_level: str = \"INFO\") -&gt; logging.Logger:\n    \"\"\"\n    Configura e retorna um logger formatado.\n\n    Args:\n        name: Nome do logger\n        log_level: N\u00edvel de log (DEBUG, INFO, WARNING, ERROR, CRITICAL)\n\n    Returns:\n        logging.Logger: Logger configurado\n    \"\"\"\n    log_levels = {\n        \"DEBUG\": logging.DEBUG,\n        \"INFO\": logging.INFO,\n        \"WARNING\": logging.WARNING,\n        \"ERROR\": logging.ERROR,\n        \"CRITICAL\": logging.CRITICAL\n    }\n\n    level = log_levels.get(log_level.upper(), logging.INFO)\n\n    logger = logging.getLogger(name)\n    logger.setLevel(level)\n\n    if not logger.handlers:\n        formatter = logging.Formatter(\n            \"%(asctime)s - %(name)s - %(levelname)s - %(message)s\"\n        )\n\n        console_handler = logging.StreamHandler()\n        console_handler.setFormatter(formatter)\n        logger.addHandler(console_handler)\n\n        if os.getenv(\"LOG_TO_FILE\", \"False\").lower() == \"true\":\n            log_dir = Path(__file__).resolve().parent.parent.parent / \"logs\"\n            log_dir.mkdir(parents=True, exist_ok=True)\n\n            today = datetime.now().strftime(\"%Y-%m-%d\")\n            log_file = log_dir / f\"{name}_{today}.log\"\n\n            file_handler = logging.FileHandler(log_file)\n            file_handler.setFormatter(formatter)\n            logger.addHandler(file_handler)\n\n    return logger \n</code></pre>"},{"location":"src/utils/#src.utils.database.Database","title":"<code>Database</code>","text":"<p>Classe para gerenciar conex\u00f5es e opera\u00e7\u00f5es com o banco de dados. Segue o padr\u00e3o Singleton para garantir uma \u00fanica inst\u00e2ncia de conex\u00e3o.</p> Source code in <code>src\\utils\\database.py</code> <pre><code>class Database:\n    \"\"\"\n    Classe para gerenciar conex\u00f5es e opera\u00e7\u00f5es com o banco de dados.\n    Segue o padr\u00e3o Singleton para garantir uma \u00fanica inst\u00e2ncia de conex\u00e3o.\n    \"\"\"\n\n    _instance = None\n    _engine = None\n\n    def __new__(cls):\n        if cls._instance is None:\n            cls._instance = super(Database, cls).__new__(cls)\n        return cls._instance\n\n    def __init__(self):\n        self.config = Config()\n\n    @property\n    def engine(self) -&gt; Engine:\n        \"\"\"\n        Retorna o engine de conex\u00e3o com o banco de dados.\n        Cria um novo engine se n\u00e3o existir.\n\n        Returns:\n            Engine: Engine de conex\u00e3o SQLAlchemy\n        \"\"\"\n        if self._engine is None:\n            conn_string = self.config.get_postgres_conn_string()\n            self._engine = create_engine(conn_string)\n            logger.info(\"Engine de conex\u00e3o com PostgreSQL criado\")\n        return self._engine\n\n    def execute_query(self, query: str, params: Optional[dict] = None) -&gt; Any:\n        \"\"\"\n        Executa uma query SQL.\n\n        Args:\n            query: Query SQL a ser executada\n            params: Par\u00e2metros para a query (opcional)\n\n        Returns:\n            Any: Resultado da execu\u00e7\u00e3o\n        \"\"\"\n        try:\n            with self.engine.connect() as conn:\n                result = conn.execute(text(query), params or {})\n                return result\n        except Exception as e:\n            logger.error(f\"Erro ao executar query: {e}\")\n            raise\n\n    def dataframe_to_sql(self, df: pd.DataFrame, table_name: str, if_exists: str = \"replace\", \n                          index: bool = False) -&gt; bool:\n        \"\"\"\n        Salva um DataFrame no banco de dados.\n\n        Args:\n            df: DataFrame a ser salvo\n            table_name: Nome da tabela\n            if_exists: Comportamento se a tabela existir ('fail', 'replace', 'append')\n            index: Se deve incluir o \u00edndice do DataFrame\n\n        Returns:\n            bool: True se bem-sucedido, False caso contr\u00e1rio\n        \"\"\"\n        try:\n            df.to_sql(table_name, self.engine, if_exists=if_exists, index=index)\n            logger.info(f\"DataFrame salvo na tabela {table_name} com {len(df)} registros\")\n            return True\n        except Exception as e:\n            logger.error(f\"Erro ao salvar DataFrame na tabela {table_name}: {e}\")\n            return False\n\n    def query_to_dataframe(self, query: str, params: Optional[dict] = None) -&gt; pd.DataFrame:\n        \"\"\"\n        Executa uma query e retorna os resultados como DataFrame.\n\n        Args:\n            query: Query SQL a ser executada\n            params: Par\u00e2metros para a query (opcional)\n\n        Returns:\n            pd.DataFrame: Resultados da query como DataFrame\n        \"\"\"\n        try:\n            return pd.read_sql(query, self.engine, params=params)\n        except Exception as e:\n            logger.error(f\"Erro ao executar query para DataFrame: {e}\")\n            return pd.DataFrame() \n</code></pre>"},{"location":"src/utils/#src.utils.database.Database.engine","title":"<code>engine</code>  <code>property</code>","text":"<p>Retorna o engine de conex\u00e3o com o banco de dados. Cria um novo engine se n\u00e3o existir.</p> <p>Returns:</p> Name Type Description <code>Engine</code> <code>Engine</code> <p>Engine de conex\u00e3o SQLAlchemy</p>"},{"location":"src/utils/#src.utils.database.Database.dataframe_to_sql","title":"<code>dataframe_to_sql(df, table_name, if_exists='replace', index=False)</code>","text":"<p>Salva um DataFrame no banco de dados.</p> <p>Parameters:</p> Name Type Description Default <code>df</code> <code>DataFrame</code> <p>DataFrame a ser salvo</p> required <code>table_name</code> <code>str</code> <p>Nome da tabela</p> required <code>if_exists</code> <code>str</code> <p>Comportamento se a tabela existir ('fail', 'replace', 'append')</p> <code>'replace'</code> <code>index</code> <code>bool</code> <p>Se deve incluir o \u00edndice do DataFrame</p> <code>False</code> <p>Returns:</p> Name Type Description <code>bool</code> <code>bool</code> <p>True se bem-sucedido, False caso contr\u00e1rio</p> Source code in <code>src\\utils\\database.py</code> <pre><code>def dataframe_to_sql(self, df: pd.DataFrame, table_name: str, if_exists: str = \"replace\", \n                      index: bool = False) -&gt; bool:\n    \"\"\"\n    Salva um DataFrame no banco de dados.\n\n    Args:\n        df: DataFrame a ser salvo\n        table_name: Nome da tabela\n        if_exists: Comportamento se a tabela existir ('fail', 'replace', 'append')\n        index: Se deve incluir o \u00edndice do DataFrame\n\n    Returns:\n        bool: True se bem-sucedido, False caso contr\u00e1rio\n    \"\"\"\n    try:\n        df.to_sql(table_name, self.engine, if_exists=if_exists, index=index)\n        logger.info(f\"DataFrame salvo na tabela {table_name} com {len(df)} registros\")\n        return True\n    except Exception as e:\n        logger.error(f\"Erro ao salvar DataFrame na tabela {table_name}: {e}\")\n        return False\n</code></pre>"},{"location":"src/utils/#src.utils.database.Database.execute_query","title":"<code>execute_query(query, params=None)</code>","text":"<p>Executa uma query SQL.</p> <p>Parameters:</p> Name Type Description Default <code>query</code> <code>str</code> <p>Query SQL a ser executada</p> required <code>params</code> <code>Optional[dict]</code> <p>Par\u00e2metros para a query (opcional)</p> <code>None</code> <p>Returns:</p> Name Type Description <code>Any</code> <code>Any</code> <p>Resultado da execu\u00e7\u00e3o</p> Source code in <code>src\\utils\\database.py</code> <pre><code>def execute_query(self, query: str, params: Optional[dict] = None) -&gt; Any:\n    \"\"\"\n    Executa uma query SQL.\n\n    Args:\n        query: Query SQL a ser executada\n        params: Par\u00e2metros para a query (opcional)\n\n    Returns:\n        Any: Resultado da execu\u00e7\u00e3o\n    \"\"\"\n    try:\n        with self.engine.connect() as conn:\n            result = conn.execute(text(query), params or {})\n            return result\n    except Exception as e:\n        logger.error(f\"Erro ao executar query: {e}\")\n        raise\n</code></pre>"},{"location":"src/utils/#src.utils.database.Database.query_to_dataframe","title":"<code>query_to_dataframe(query, params=None)</code>","text":"<p>Executa uma query e retorna os resultados como DataFrame.</p> <p>Parameters:</p> Name Type Description Default <code>query</code> <code>str</code> <p>Query SQL a ser executada</p> required <code>params</code> <code>Optional[dict]</code> <p>Par\u00e2metros para a query (opcional)</p> <code>None</code> <p>Returns:</p> Type Description <code>DataFrame</code> <p>pd.DataFrame: Resultados da query como DataFrame</p> Source code in <code>src\\utils\\database.py</code> <pre><code>def query_to_dataframe(self, query: str, params: Optional[dict] = None) -&gt; pd.DataFrame:\n    \"\"\"\n    Executa uma query e retorna os resultados como DataFrame.\n\n    Args:\n        query: Query SQL a ser executada\n        params: Par\u00e2metros para a query (opcional)\n\n    Returns:\n        pd.DataFrame: Resultados da query como DataFrame\n    \"\"\"\n    try:\n        return pd.read_sql(query, self.engine, params=params)\n    except Exception as e:\n        logger.error(f\"Erro ao executar query para DataFrame: {e}\")\n        return pd.DataFrame() \n</code></pre>"}]}